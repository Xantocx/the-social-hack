{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "# The Social Web Assignment 4: Recommendation\n",
    "\n",
    "- Instructors: Davide Ceolin.\n",
    "- TAs: Jacco van Ossenbruggen, Elena Beretta, Mirthe Dankloff.\n",
    "- Exercises for Hands-on session 4 \n",
    "*****************************************************\n",
    "\n",
    "In this notebook you will use the similarity measures to provide recommendations by comparing users and content based on expressed preferences (ratings). You will also explore textual similarity using a very popular natural language processing library, NLTK. Finally, you will explore recommendations on the Reddit platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required packages:\n",
    "* feedparser, praw,  nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# !pip install feedparser\n",
    "# !pip install praw\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the snippets below, you can find:\n",
    "* creation of a small toy database in form of a dictionary of dictionaries;\n",
    "* issuing several similarity measures based on critics' preferences; and\n",
    "* use those values to obtain meaningful statistics pertaining a user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie preferences of movie critics\n",
    "As example data, let us define a python dictionary of movie critics and their ratings of a small set of movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "critics = {\n",
    "    'Lisa Rose': {\n",
    "        'Lady in the Water': 2.5,\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 3.0,\n",
    "        'Superman Returns': 3.5,\n",
    "        'You, Me and Dupree': 2.5,\n",
    "        'The Night Listener': 3.0,\n",
    "    },\n",
    "    'Gene Seymour': {\n",
    "        'Lady in the Water': 3.0,\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 1.5,\n",
    "        'Superman Returns': 5.0,\n",
    "        'The Night Listener': 3.0,\n",
    "        'You, Me and Dupree': 3.5,\n",
    "    },\n",
    "    'Michael Phillips': {\n",
    "        'Lady in the Water': 2.5,\n",
    "        'Snakes on a Plane': 3.0,\n",
    "        'Superman Returns': 3.5,\n",
    "        'The Night Listener': 4.0,\n",
    "    },\n",
    "    'Claudia Puig': {\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 3.0,\n",
    "        'The Night Listener': 4.5,\n",
    "        'Superman Returns': 4.0,\n",
    "        'You, Me and Dupree': 2.5,\n",
    "    },\n",
    "    'Mick LaSalle': {\n",
    "        'Lady in the Water': 3.0,\n",
    "        'Snakes on a Plane': 4.0,\n",
    "        'Just My Luck': 2.0,\n",
    "        'Superman Returns': 3.0,\n",
    "        'The Night Listener': 3.0,\n",
    "        'You, Me and Dupree': 2.0,\n",
    "    },\n",
    "    'Jack Matthews': {\n",
    "        'Lady in the Water': 3.0,\n",
    "        'Snakes on a Plane': 4.0,\n",
    "        'The Night Listener': 3.0,\n",
    "        'Superman Returns': 5.0,\n",
    "        'You, Me and Dupree': 3.5,\n",
    "    },\n",
    "    'Toby': {'Snakes on a Plane': 4.5, \n",
    "             'You, Me and Dupree': 1.0,\n",
    "             'Superman Returns': 4.0\n",
    "    },\n",
    "    'Amy': {\n",
    "            'Lady in the Water': 3.0,\n",
    "            'Snakes on a Plane': 5.0,\n",
    "            'Superman Returns': 4.0},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exercise 1: Finding Similar Users**\n",
    "\n",
    "In the code below, two different simililarity measures are used: Euclidean distance and the Pearson correlation. If you are not familiar with them, we recommend you look them up to deepen your understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidian distance"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzUAAABECAYAAAC4ehsVAAAABHNCSVQICAgIfAhkiAAAIABJREFUeF7tnU2MZUlW36eKkSwzkruqkTcg0a/KtmwMQ2cNtoRZTL1se01njeQl7sySZe/oqjaaBcj0y2LDBshqFvbC9rxs75DMZCHZG0tTN9uWLSGYrhowHwumXmHMAiQ6G1kW/gD8/1VHDFHREffjvZfvI/N/pH/de0+cOHHiHyfixn33vazPfMZiBsyAGTADZsAMmAEzYAbMgBkwA2bADJgBM2AGzIAZMANmwAyYATNgBsyAGTADZsAMmAEzYAbMgBkwA2ZgMANXBtdwBTNgBsyAGTADZsAMmAEzsLkM/JRCuy/86eaG6MgWYOB11Z3l9T+bK3xtBsyAGTADZsAMmAEzYAa2mIEvKPYvC7+/xX1w6HUG/qBe5BIzYAbMgBkwA2bADJgBM7D9DPAtpN8V/G2k7R/LQT24OsjaxmbADJgBM2AGzIAZMANmYHMZ+E6F9nvCn29uiI7sPBj4tvNwap9mwAyYATNgBsyAGTADZmANDHxRbb4i/PsBbe/I9qeFkfAn4Xwv1P+tAX5sagbMgBkwA2bADJgBM2AGzIAZWJiBn5CHfzLQy4nsxwJvdx6GuvF6oCubr4sBf/1sXcy7XTNgBsyAGTADZsAMmIFlM8Bfxvr6QKdHsh8JT4W3Q91rOn480I/N18iAH2rWSL6bNgNmwAyYATNgBsyAGVgqA98jb0MfahrVGQunSSR8/ezRUiOzMzNgBsyAGTADZsAMmAEzYAbMQAcDn1P50Aea6HKmk/g7GnRnwh1hHA183GwG/P/UbPb4dEX3vTLwGHax5HIzYAbMgBkwA2ZgCAO/IeP/O6TChth+XnF8Y45YRqrzmtCEumMd+WMDXxWmiT4U+7CJDHhDvImj0i+mmzL7D8J39zO3lRkwA2bADJgBM2AGejEwktXzXpabZXRL4fC7mKHC72eOBd7OIE8Evno2Efi9jWULGPB/TLQFg1QJ8R3p/5fwC5Vyq82AGTADZsAMmAEzMA8DbO7/bJ6Ka67zL9U++6KvrTkON28GzEBPBngY5cdsN3ra28wMmAEzYAbMgBkwAxeZAfZGvyxcv8iddN/qDPivn9W52eQSJiyvSmebHKRjMwNmwAyYATNgBszAihhgT/sdQvwK2YqadTObwoB/U7MpIzEsjj2Z891P/pMoixkwA2bADJgBM2AGLjsD3ycCfl1I90a8vYk/tUCf/uwiv4a/kq6L1238ml5Xn7ay3G9qtnLYPvOmwj7ZztAdtRkwA2bADJgBM2AGls4AfyTgw8zrR7r+0wAePuI5x/y6pkvrlM75kNliBszAHAzw1bPnQvppwxxuXCVhgK/y8T8IPxbeFbi2bC8DI4XOX6vhT3HG/xl6e3vjyLeRAdYQ1pKYg15TtnEUL3bMO+oe6+RXhLcuSFd/Tv3Yy/pyV9e8fYl4qPP49qZ2xEVexkuAN4QvCe8JMyH1y1+ktSyPgYuYn8tj5wJ5ihPqAnVp7V2ZKgImEBsPzvlkx5uQtQ/LXAGMwhgyfpw/EdhYWszAqhiI68hIDXLeCB+G81XF4HbMQBsD3O+mISc5nwk83Gy7PFYHRoVO8CYlfQBhH7Wo8NDDQ84s+D5c1KHrf4uBi5qfHuICA0zOLxT0Vs3HAJOHxW4vVGcTwrUXqPn4XHctxo2H0lEIhHFlPPlagsUMrIKB3ZBz49BYXGMOVtG42zADPRjgbUX64d29kLM3etTdVJMrCmwmcMyFb7hQFh9s6Psy36wcyx8+S23nsfi6m4HDwCf7MaR3fi7jNzX7avAoNLxpBybo6aYFtUA8TJjXBT71qwlJcCLQd8snDMBHbVM7U9mjhKizcP7ahpC3oziaDYllE8IYBT7iYpfHxNxgzsdxjMdXckNfL8TAgWqzMbqs8kQdZ26W5JmU5OAsFGKLbMqaEsLZ+oPXxvoQcv9vhNo6+Vhl6Tp5EXKU+fXNCiU8cKRvZ+Dl31Vs51Hvq9IHAutiXzmW4Z2+xhfMbqT+kHO1/Mzv40vLTwg/FBrhpEAqG8WnAk/Bmyr8J5XTTQ1uYFxMyq6NBIM/ZGINDGErzVngZwL52iUjGfBpzl6X4QrKiXcmEL/lLxjgO9LckK/0IGUimzOhtnj2cGGTjAHWl3iTuazk8LYcDvrc+1hLWFN2LitZ59DvuDb24f8cmt8Kl0P2PkfqEevkNssdBf+zHR2Ak/i2huODDvshxdxjuvZn0R8PNH1th8SwTbZryU+SBPIZ/JOMLRYTnn75TuGmS6MAl5m86+ovY5F+2pDHcSjFo1zp6xcMsBFue8MVaWp0Mo0Xaz6yaSJuy6cZIM+5EbcJNxnWqP02I5cNYoAHbDhlU3/ZhZty15pCDmJz77KTteT+z+TPa2M3qY1MuvY+O7KBT47bLOx/fqRHBxrZpA82q97Dsq+eCeyhL7twH3+vg4SYn+MOu97FbKJJgPtZDRLotLeX9RqStGfCNifRFcX/ROBYkrjZ4Gj5NAPwNhPaboQTlU8/XXUuDQvXInKgyrNFHFzwujfVP9YljiVhM9kIe6XCgToW1W2/4dPl0RL6cSwf04H8XVRz7ifcV9o2RXC1vwQCyOeLkIP0Y9E5yV7kyRI4vQwuuvY+jEcj3LoAZHxVffh8j37EeRsfbPiQZlV7w7gP4f5u+WTtZA19tULGueTnQzXG4KefzJEAJELbW4NKjGtRx0Tq+sRiLcH1bBT+2VDU5H0VnNYKrX/BAAvJM4F8yGU/lEf9vdxgwPVV2TYD7HPTmK/cvC11BuC4NieOVLYTqnKM53Vv9RLWjcN68daUsMFZpB88QOb3gq3p/DkFyv2xEUprylT6/dAuN+d4HlSDDouO3aDGztGYfjQL+IdnNkGs5ZZ+DDyRWWnvQ042Qlwb95Lzfp43x4q8+G2h738ovyvb9G3NyYq6clftkL+l9WJFIWxcM33zc6zIY65WO8Hmq00g/rbwsZC+Zr+jaybEqhKhLcY+ZSTvLwm8mtzWZNpX7I9aOvvDKjttKXfRJ/yMRAQLWir7uiDPeeDh+JZAfs8rnROvw/Etlb8meDzbiWJOk/f5nJ5Kx1gyhozn2+FcB8sCDOypbn4vWMDdhajKmkyO3ch6c6DrPxdmoZwctCzOAHuPVwSvjf25rO19JnLB2424TnLfm/V3u1GWn1M0fyz8v55RPZbdTyW2b+r8nZ51FzGL+zTWBssnDLCGlvbmR9Kn+ckaejYPabwRmAj7wnUB8vPNNNeNkMtIikNhIjwUCIrFHt004L6O+F1EeEM0EfCP73hD2dV5I1wRcqEOfeHTxm0T+jMTSv2iL4wZfeNTsJLEMb0VCuH/IGDRsSi1t2wdY0be3AmOWYTj+ZC2Io/pp1YjOfhIgL8UbODmlZiH89YnvrbJy9jBBzwg8HNPmIeT4GKlB/g5FGI+crwxRwTkO2NGfkeBh3wsF72BMB7Eu+0CX4v0o1F9UBJyEe7JzSiMazrOpXrr1pF3xAzifBoyj66qHvl1N+nITtDleThObIaeLjp2Q9s7L3v60Szg/D3VnbXUZxzTtZG1YZvWRrpGTsa5dD30dUhO5vSU9j4TGeX5ueg6mbe7yusfVGP/amCDV2T/JOMhvZcMdNdpTntw/E7FknE/FHZDOWPPuJML3OM3VfI5RtyxD31ijvfxtI/0ea78ZEGOwoJ+Ivwb4blAUI9DYRONdGRgXgs2ifrFKZ3hifdd4UcFnqw+FFjkf1cYC/x1Cv7sHrqhQowkIX+Kj04TCzramAjEfjvodXhJYl8o7yP4Hoo+fuexuaVKTwUGuSSRS7jJhbrwQl++LtwXePo9E0bCM+GGsKnyUIF9TSBe+vlIIGb6NVTg77nwxaQifln0mVgpmqHOl2hPfIw3Y5bLoRTjAHJ6Ivyk8A2B+RbzXKcbJyNFxFwlTvr3rjAVyMvrwlCJfb2dVDzReT6WXC8i5M1lF3KR+fdBhYip9NjEMWUc9oQnAusNm9FNE+YS+XhNIP+acL0/INA/ky25nObgTNelHMT/ZZdF59L3i0D4LQnjSY6yvpB/R+GctZG8RLfpEnPyYwVKTrLGkaPMpXml7zo5ZEPPXJ8H8/ahq97rMmCchwi5yL0frqOwt5znXtSnXXITYU3MhTZZJ4mJ/c5EmAroiY975B1hk4R1kznF/pIYyVH68E0h9rVPvOQ3kq6h+M3X0CH5+cIhRM+EdECf6hqSU2ckMroHQkliOTYz4WZiBAlnAmUfCUOTpwl1qf8DiV/ii34pu5qUxVN0bXGnVSAT26G4W2h3GSq4bvPNQkiscJ/LsRTwsxtsGGfGAYljhc0mCnExrmmeNLqmr/RnHnmoSs+EElfz+CvVIbamVNBDR1zMu1p9xg8b+gEP9xKftIuuLVcS85WeMoYsXidJq+jiHJtnPKhDfebHecqhnINtF9a1efsR189SfdaXR4Ec8pMxGSdkUQfdjUS37lNyhphuJYHEOXV/YHCN7ME8Ody3qUXGrm8bq7DbDVzN0xb8cj9gnHJhLYlr41TntbURHjdVYv6lOXkc+nKwQNBx7i5znWQdj2t33+NsgT50Vf15GaQfVnbZp+U82KR9gPPzEHKPdpgDubwjxV3hWrCZhfNo1+jkWbzYkCMxzQTmXpSnOsnX1aS4eLrU/MQZQrLzpHso8LCBxAX6Y53HJ6lUH8yKh+dBO9MxHQgWpPdDGYN3p1i7rGSi3w5Fpzr+amLGU+y0XO1bWojuKzwpw00J8FLSo+OJdYjAQZfQ3psCT8A1SZMqt2Fc4WccCu7pyDikwqdfcbxHOn9XmLxs0nlF/SHocnhXBv9IYKGPOUkd8hEhBxD6vi9MP7ns/Jf6o06r/ga1PuOhraytBcbjg4LBrnRPg565QF+OErs4hq8F3Z6OU+GJQP6MEtuu01rsNX2XP+LcEe4nhulYMj+Jbyo0wmPhjtAl8EGOL0O6+tZVXoqBPsM9+dwmD1U4bTMIPvCFzzapxRnzo1be5nMcCmP+pbasTyfCdYGxOBWaxCC2eyPRTXSe5m5SVDytxVzSFx0kyl2d/3PhWPgw0cc4iT/KPZ10xRljSKotdFrqU4ytrazW6DUVkDeTmkHQMzcZR+xrcksFzM03agaJvi3WtrI216+oMK4bqR1zogmKcbBJxy3yF/cQbW30KavFX9N3+YTPHxWOhTQnY19Puxy0lA/Z+7S4ealoT1e1fVBNf6Ov8znsuGf+2hz1qPKLwvtJXfYdPOgsW8bBYWkN/WGVpfOK3D1LAiCvRkLMY4qYq4xDH6nlZU3f5fOBDJhLh8JHwTjGRs4+SRxMdb6fXOenS89PApkJOH41aY1zdI+yCEhY9HSqJPhrgg3HdBCwpx7123xgl0tXPciNfomxJEPbLPlYpg5u3+hweFPl+RjkVShvSwzG4DTYpOOBb+qRgOiZSBNhFo469JI0h+IYdB1pq01mKsQHMUahHSY6fUH2hanQBKDrkphHtRzpqp+WT3XR1c9SedqnUntdeVqbm3zaE+uOdE58UVgAnwnXEl3tlE/eS3G36ahTkxvB30zHNP/I/bSvja5Hwcl+KNsN17UDdcAyZCYnbX0slVGnTWK+xYW/ZBt5wD/nNZmpIOWrZsd8LsXapsN3m8QY2+JjI0Ab5GEqcX1K605ksJfZ1S4bFbTFnpdNa46CPsZDvFHISzYbrC9pju7ruivO92VDDMuQafCV96ntmty62tJ4HBd81OzQxzYetPhqgh3HNpkGu7a4S2U3W5wyLtRpi4/62BxnfqjTVbel6U8VzYK/Uh9KuumnPLysGJKTHa6KxcTUtY8oVtwCJXnBmpfO26FhXw8+4tjNhjroYR9zsDYHcfGeQAy3En/0i3UJfVp3quudxK52GudEKS9rurs1Z9Kn8bya2HFeyrNJjzhnsjltaXNQEZsRAsmTonaDglTsGaCS0OEm2HDME+0wlLX5KPlN63GeS1peShriGNIm9kORx9R2HZOXY5u8o0LQJnGy5FzHOrHvTebkQNdwcpzpsZtkuq7LZXLFhCaumZD2KeZqnnvE2nQFGMq7uOrp5ltmpX6/EeIpldXGKDqkfCbkfUzjinPzfhYs4whvd4VJOI+L3m645thHarHX9G0+yV/iepgZxbGAr2vBZpLYsJDTp5oQC+vWac1goL7Wt0P5IdZaeVsz8N8IjEmb0M9pm0Hw0ejYdSOrxfn3VZe+1Mrbmr+pQsaQ3KtJXNPyG/Is1MXHPFKLt6Zva4M69AO8mhhyjm6ejd+p6s0EfC9DSv1aZOyYW/TrqCM45ueJMGqxYw1uhK58xkWpH8x16pfKuviLY8dcrAlxMY4HmQH96srfms+SvhZ/TV/yEXWxX8R3NTFcJCfT9vrw1hZfrazW1zZ9zdci+huqPM+8zduM+w7GgTxdtsTcTNedvA3uZ2cCHEaJcc0yfWLSedo2JqWyNodwA0enWTzcG9C/01a5UBbz87hQNlj1WdVgwUMIkICixBvnYylGAY2O0Sa1/Ytaw85mA8yfJrbjAfWiaZokXdUZtHe7jArl3BR4ldklJPftYMT3QOOg5vXQvyXcyQsGXu8Ge8Y4lXG4WEYyLSMfYmzXwwljnvqN8ZKT8wpfX1imlPoddaWyPm0/l1Hb94PHwUmTOCNX3hQ+FviqyWuhjEUSGRrLUPvQTPEQ15h0DhPv7WDNeNLefaFJPLC4x7qJ+qXT13XF96mXIW19pqytvNY+/I9rhYn+rR42fL21z1dca3FGfa28LYRZKITv0hrHeFJG/sWcowr3kdeED4RvCoznRJgJR0IfmSfeml/iRMjF9O3ZOOibcCTOe8KZ0BUn8TFnlyWl/i4ydvSBtaFL3u4yUPnXhXEPO0yW3Q98Mm6vtLR/O5Q1iQ33E/rPGH1VYGzfFU6FRtgXyNFH4VqHTin1rbNSxSDm5DdUnvodB/smHHd0pB9wgI78xJ64nwg1if6XGTNz4latwYqe+bZXKaup/6oK/rBWGPSv6wh3iwo8MVf+mfC1RZ0V6s+CjngfF8p52KGM8UzHajfYvh/0aR6cFPyUVMsc++ifnCvla+wbcb4lMM/a4oz5yfxcivDJC4EdZt5mumaAEZ682IhHoTPHyXV+2kiBzw8FFpQoBD8TKOOYluEfMiCiJNgSD3WZHGldziPBlF8tOMCGsoNCWUlFrENR8pPr8HkqEGPsz83cKFyT5E8F6rQJfaJv2JfkQSjfTQqxpQ4TKJdGikmuXOF1jO0wa5O4SuNLrJT1Ebjva9vHX8kGnhdpgwWAOGvjHnM9bZv5AzfM1ZJMpZyVClagi7Gl+XdN7RJvU2l/HMo51gR+8JHnSc1+Xj3+z7uNeWMbUu+NBfoB16xXrCUliWPRZIXv65ox4j6DTIU49jtBt8pD7EeTNco6mMZ5lMQ57ggQX6V1tKPaoOJFxm5QQ+dszBoAX/MKddvql9ZG1kTG9kuhUcZ2FHRTHW8k18FkpYfa3Mlzklj3BPY/nBM318+ENhm692nzFcuIeR708R1tvl0n0x4VDmXzD3vYtZnAJbzW1re2un3LbsmQPGQul4T8LN3PZtKT14wja+dUGAtd4y6TcxHiz+MkLuI5E8gLZCqMBWzbJObn/TajljLm81QghhdCABB2Es5pgIcRgiPIWI4+yrFOmuQ6PcWeMjoC8HVH2BUeBx2+0aUS7R9l+vTyli6oG/2OdY4f2oj1OV5NK4XzmDDx5lowWbmKvhLv3UrL6Gub1LTKzeCnNFkYj9NQzhgjjCVjDtJxDcUvxu8wXqzpSMzkC/FfE6YCXKFHl8pEF02mK11Sbya8Xypcom5XvpoF/DHmLLAleVXKmOv3gwE5jf1xqYJ0OwLzhuM6hByj/Rgv8zjO2QeVgMjNg0pZVNNvuCjlfUfVQcWHsgbbLvC0SD9Yr0BJ8B3zkvFFWL/QxXFkHu8LewL5sC55qIafCeQlwrwhTmK6EnT3dGS+oCfumlwNNrU8rtUbql907Ia2d172u3LcLOCc/GXsSpKujbSDlNZGxnYspGMbxzpUW/mhKyfJwf2AmY4xJ/d0znWbxLm5SXuftnhj2Zd18jtCnJO1Oicq+Bu1wh561gHuR6wD5yn040yo7eneUxk5SX7H8SUm6sQ1lfHeEY4E+r0OoR9PQ/ucR/6I/VEIiBjHwj3hSdDVDjE/OQ6Vm6pAu+Cl+iMpIIjGTwWSHxKfB92+jqnc1QVOrmZ6LulkE8o5YssR3xwZpBtCLtEOmzahLj6wI1aO++EYO1eK64FszoRNkshjTIQ8NvQ3c2XhGs5nQmmyUAYvjfBQiGMMHzXB9rBWuCL9NbXDODN5iOe+QD9KcU2CjQ6tApf4gPfzlF05bxZoIG7WS2N/R34jD7TxWGAeoC8JPDbCTqlwhbrICflHXjO29AN9LlMp9nNl4Zp8x8f1QtkyVeRcKe+W2cYqfL2xYD/gm4fnK4Vg4YexOBDiGsM43yrYTqVj/NclzImHwqnQCHFtId5UjnQxzXT5JZzS7/PeMC46dnnc67pmvjcLNB75frXggzWQsWA8aYONKmOKPpeJFE2ipA55uy6JOflBiKuWk1OVP0yCZB51zaUHsjlbV8fmbPdzqvcHAuP5l1t8sBb9psBxHqHeU6GZp/IcdchHUBLyj3FifxJjYmyvF4xn0t0p6FelGqmhE4E1lP6wVsa5l8Yw08VBqiicL5qfzAd4Yg59SvLEyK9jBUj+WPjSpzx8+qGm5qNQ9cXXpyBpHmlUCVLB1YIDkoTOb5LQX+ItbRQomwl9+SMxmkLn4k3gMJT18YefScHXOlQx3riBpT+5EGuTKwvXB9KxaJQWiYL53KrdnvHUGqDPM+F+weA96ciZW6GsbTyZ5FMhTnbi2iv4XKUqxtuoUfqRx0+8+0lALJw1oey4VrhE/aF8gW0X5s4i/bip+mnuRT4YQ9bXdDzzcY225GL0sbNmQokR7IaYWGNSYa2gbJTp00vuKc+FWn9bqg4qWnTsBjV2jsbw2SzgH55nwt2Cj2PpyK0boaxtTBrZTBIfT3TOekt+gnUJMYM7An3Jc3Im3X4SHDm6J4wSXX5K397PlRt+/eOKj/6DL7TE+h0q+08t5V1F5Az8nPeeIMZB3tb2e/T1UTCMeVCKn/Fm3JGdksEKdXGOHarNfKyIjTivCaOWmOCfcVi7PKgEQicbgQ5yjJ3uE/CBjPJJ3KceNrQVJ8HVrBI3BMi90dfZiuzgJm4GiDEVkp8NbF/hIShd0GO9mGy7fR3JrhGot0nCZKd/pXyaSN90BEu9mbCKfjGJ9zri6Spm/PmkMRcWAHK5xENqSwzUPxImwrvCY2EsrFuInbE8zQLZ1/VXhYlAvD8XzjOzF5c3hVK+l2wX1e3IAdh2GS2hH8fyAVJhQ1Aaz8zsxeW+MAsF03Bc94EHE+JPN09jXc9CYNNKgPSbDcpBpXyZaubzeJkO1+SLfuwt2DZrI2tZKqwpz4VZpq9dMt7jUEhMXI8E1kuu1y2lnCQ+4ozxjcM1sU75pyDsK1a1Thaan0vFXuZXhF8Isb/V4uUfqGzePxTD/upMuNHif9lF5OlMIIdTuaMLxqnP/ncqO/J0R7j3kpf1XTxR03BJ/6JMdDIVRgLnJdmo/GRBpxO3kkhJjkPhmcAAceS6T9LgD2I4DhFIfCDENmmXNncTJ6dBN8TvqmyJnZjzB5hj6dKbbJ948EG9KCQMG1v8j4WucZjIBjTCSThn4qxTaH8s0Af6wvm1EBBlRwKxNsIkIBS/dICLmRDrlmw2TfdEAX0pBEXce0Lkgfxu68u9YIt9inX3kbjfDjFNdRyHgHayOGPM+6E8P5Dn01zp63Nn4KZaOBPiWsIxjudXdD7uiGCkcvL6SOB8nUL7Y+GZkK+RlMU4yc2SsAFpSgXWnTsDjA1rOkIO7gnp2hiKigfGkxxOBX8TYT/Tr/pypAbHQpqT6BD0TTjnMBJmwlSo5egjlR0K2yQ/qWB/RPgJgTH9mZbgf0xl/7ilvFZ0VwXkwNA9Vs0fevau3Je6hHv6LDFiD82HefSVtTTdU5d8keuNcFQqXLGOvHtTSOfetRBDGmfU5eFtXH6SEKdCfBBhMJoCugaJju4Lu5wMlCuybwTiiOD6IPjhxvMknG/iAQ5JCGKkLwjH9Dqoex1IkjsCnNc46eVoQ4xOFEcTQH84ZyINEfLzudAnD4f4PW/bGyFu4iefY//n5eG84+3yz7g1hX501cvLuSkwP+DFsnoG2Ew2odkjHfN1ZvURzdcisdOPNP74IUKXR9btmbBta0pXv7alHN7jGnA/jGGjY8RoWzqSxblITuZd3vS9Tx5vvP5r4SRulv9jzVD6fyswF4cI6xd7rvhQPKRum+2hCkEfeS/YXtExXX84Jwe2RRoFmmPUM3geLJnD13rar8zsQC1NVtbasIZubCppSTdI6jOBSXYz6LmxkvTzCAnSCKOkMm1cZjlR53e2lABu3s2Wxn4eYY8CHxu3EJ5HZzfYJzekbbr5dlHJGjlknWxkv61rShcX21LO2sjaflFlaE6mPGzD3qdr3PiLZuyL/odQmpvofl34S12OknIegD4SWL+WKfgjVnjvK1MZ7gXjUv/6+tlGO3hqBN/Ht3H0esR8LBsmRJxoXC/7U4QeYdjEDJgBM2AGzIAZMANrZ4CN/v8W2Bv9lUI0PMw8Ffo+EPBmnweaBwVf86r4IHoqEOOjeZ24nhm4aAzEp3wmBRN0Fo4XrZ/ujxkwA2bADJgBM2AGuhhgL8QfDOCB4YcKxn9XumlBX1LxQPOhwAfG8SEofRhKdZxH4Cstu6prPnC+J/CWkNgi4ofS1LGsiYHPrqldN/syA0yOfy18UWDCnApMFIsZMANmwAyYATNgBi4bA+yB/pvwA8LfEf5LRgBfJeNNTZfwUMIei6+LngmPBXyjj/useB4fYKLPaPdKqB/1+fFjKfixv8UMmIHAwBMdmUAc+U2NxQyYATNgBsyAGTADl5WBL6vj7IucHgTvAAAEA0lEQVSmBQL+hXTjgj5XHQcf+Dkv0IZlAxjwm5oNGIQQwi/p+LowEvzEvznj4kjMgBkwA2bADJiB1TPAHwJA2Bvlb1Z4U8OfdO4SvioWHzrim5dYJ7/u8lUr/2atwHozcFkZYIIywfxjs8uaAe63GTADZsAMmAEzEBn4bp2wL/oTIf1qGOd8NS3/upiZMwNmYIMY4Pue/rHZBg2IQzEDZsAMmAEzYAbWwgAPLf9T4MHmrycR/G2d8zsZixl4iQH+koNlcxi4r1B+cXPCcSRmwAyYATNgBsyAGVgbA/GPAfAgE4Uf/fP743mF+ovKaFEHrr98BvxQs3xOF/H4FVXmbY3FDJgBM2AGzIAZMAOXmQHe0MTf1XxvQsQtnX9jTmJ4oOHPO8/zYHNN9e4J7NWeCf7625yDcF7V/FBzXszarxkwA2bADJgBM2AGzMAiDPxaqPy3Eief1zkPJvMIb3h4KJr3TQ9vjvzb53mYdx0zYAbMgBkwA2bADJgBM3BJGbitfvPGhv+Ikzcj4Hk4rouScYjJb2rWNQKVdv2mpkKM1WbADJgBM2AGzIAZMANrZSB+/exvhii+S0e++jWPTFWpEfbmqew6m8+A/5+azR8jR2gGzIAZMANmwAyYgcvIwB+p078vfKcwEvhtzdcF3t4MkQMZPxTeEnioOQmVmx5OsD0q2A2NoeDCqmUy4IeaZbJpX2bADJgBM2AGzIAZMAPLYoAHh98QeKj5PoHfw8zze5qPQr3HOu4LUcbJ+dBTvn7mB5uhrJ2jvb9+do7k2rUZMANmwAyYATNgBszAQgz8Zqj9uo7fL/zqHN542xK/dhbf0kQ38bc6teMczbnKOhjwm5p1sO42zYAZMANmwAyYATNgBvowEH9Xw/9V8z3Cb/WpVLDZl+5Y2BFGAg83hwW7XMVveKa50tdmwAyYATNgBsyAGTADZsAMmIG+DPw9GfI1r98R/mvfSgW7M+nGwlS4Vijvo6L+2wLx3A7oU882K2DAXz9bAcluwgyYATNgBsyAGTADZmAuBuL/VXNTtef9TzdpeF+4JxwJPODMI2NVui7whucNYXceJ65jBsyAGTADZsAMmAEzYAbMwOVigN+6/HeBtyP/9HJ13b0dwoDf1Axhy7ZmwAyYATNgBsyAGTADq2SAh5nfDg3y55wtZqDIgB9qirRYaQbMgBkwA2bADJgBM7AhDDwNcfzKhsTjMDaQAT/UbOCgOCQzYAbMgBkwA2bADJiBbzHwyzrjgcb/L4yTosrAt1VLXGAGzIAZMANmwAyYATNgBtbPwP9RCPy25j+vPxRHYAbMgBkwA2bADJgBM2AGzIAZMANmwAyYATNgBsyAGTADZsAMmAEzYAbMwMsM/H8ouJdWva4GwAAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the degree similarity between critics given their respective preferences, we can use the euclidian distance.\n",
    "Its formula for an N-dimensional space is: ![image.png](attachment:image.png)\n",
    "Because we want a smaller distance to indicate a larger similarity, we will use 1/d(p,q) as our similarity value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def sim_distance(p1, p2, show_common_dims=False, prefs=critics):\n",
    "    '''\n",
    "    Returns a distance-based similarity score between two critics.\n",
    "    '''\n",
    "\n",
    "    # Get the list of shared_items\n",
    "    common_items = []\n",
    "    for movie in prefs[p1]:\n",
    "        if movie in prefs[p2]:\n",
    "            common_items.append(movie)\n",
    "    # If they have no ratings in common, return 0\n",
    "    if len(common_items) == 0:\n",
    "        return 0\n",
    "    if show_common_dims:\n",
    "        print(\"common dimensions between {} and {}: \".format(p1, p2) + str(len(common_items)))\n",
    "    # Add up the squares of all the differences\n",
    "    sum_of_squares = sum([pow(prefs[p1][movie] - prefs[p2][movie], 2) for movie in common_items])\n",
    "    \n",
    "    # return sqrt(sum_of_squares)\n",
    "    return 1 / sqrt(sum_of_squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this simple formula, you can calculate a similarity between two critics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41702882811414954\n",
      "0.6030226891555273\n"
     ]
    }
   ],
   "source": [
    "# get the distance between 'Lisa Rose' and 'Gene Seymour'\n",
    "print(sim_distance('Lisa Rose','Gene Seymour'))\n",
    "print(sim_distance('Amy','Lisa Rose'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this with other names so you can see who is closer or further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5345224838248488\n",
      "0.6324555320336759\n",
      "0.5547001962252291\n",
      "0.6666666666666666\n",
      "0.3651483716701107\n",
      "0.5163977794943222\n",
      "0.47140452079103173\n",
      "0.47140452079103173\n",
      "0.4\n",
      "0.7071067811865475\n",
      "0.6324555320336759\n",
      "0.4588314677411235\n",
      "0.6324555320336759\n",
      "1.1547005383792517\n",
      "0.8944271909999159\n"
     ]
    }
   ],
   "source": [
    "people_cr = ['Lisa Rose', 'Michael Phillips', 'Claudia Puig', 'Mick LaSalle', 'Jack Matthews', 'Toby']\n",
    "\n",
    "for i in range(5,0,-1):\n",
    "    for e in range(len(people_cr)-1):\n",
    "        print(sim_distance(people_cr[i], people_cr[e], show_common_dims=False))\n",
    "\n",
    "    people_cr.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name at least two problems with the sim_distance function as it is defined above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems:\n",
    "\n",
    "1. Two users with very different taste are far less likely to watch the same movies, and consequently rate them. As a result, two users may share similar ratings for a few movies, while most other movies they like do not appear on the list of the other user. As a result, the formular indicated they have a similar taste, even though this is certainly not the case.\n",
    "\n",
    "2. The formular is in no way transitive. If user A and B have a similar taste, according to the formular, and user B and C as well, this does not indicate that user A and C have a similar taste as well. User A and B might share a preference for horror movies, while user B and C both like comedy. B watches both, horror and comedy movies, while A only watched horror, and C only comedy. A and B, as well as B and C have a good match, but A and C have a terrible match as a result.\n",
    "\n",
    "3. If all common movies of two users have the same rating, the distance becomes 0. As a consequence, the similarity is 1 / 0, which is not defined, resulting in an error."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different measure of similarity can be given by pearson correlation.\n",
    "Which follows: ![image.png](attachment:image.png)\n",
    "\n",
    "Where the dividend represents a measure of covariance between dimensions, whereas the divisor is the product of the standard deviation of the scores given by each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_pearson(p1, p2, prefs=critics, verbose=False):\n",
    "    '''\n",
    "    Returns the Pearson correlation coefficient for p1 and p2.\n",
    "    '''\n",
    "\n",
    "    '''Step 1: Get the list of mutually rated items'''\n",
    "    common_items = []\n",
    "    dic = {}\n",
    "    for movie in prefs[p1]:\n",
    "        if movie in prefs[p2]:\n",
    "            common_items.append(movie)\n",
    "    # If they are no ratings in common, return 0\n",
    "    if len(common_items) == 0:\n",
    "        return 0\n",
    "    '''Step 2: Sum calculations'''\n",
    "    n_common_items = len(common_items)\n",
    "    sum1 = sum([prefs[p1][movie] for movie in common_items])\n",
    "    sum2 = sum([prefs[p2][movie] for movie in common_items])\n",
    "    # Sums of squares\n",
    "    sum1Sq = sum([pow(prefs[p1][movie], 2) for movie in common_items])\n",
    "    sum2Sq = sum([pow(prefs[p2][movie], 2) for movie in common_items])\n",
    "    # Sum of the products\n",
    "    pSum = sum([prefs[p1][movie] * prefs[p2][movie] for movie in common_items])\n",
    "    # Calculate r (Pearson score)\n",
    "    num = pSum - sum1 * sum2 / n_common_items\n",
    "    den = sqrt((sum1Sq - pow(sum1, 2) / n_common_items) * (sum2Sq - pow(sum2, 2) / n_common_items))\n",
    "    if den == 0:\n",
    "        return 0\n",
    "    r = num / den\n",
    "    if verbose:\n",
    "        print(\"common dimensions: %s\" % len(common_items))\n",
    "        print(\"Similarity Score for {} and {}: {}\".format(p1, p2, r))\n",
    "    return r\n",
    "\n",
    "# for k in critics.keys():\n",
    "#     sim_pearson('Michael Phillips', k, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the examples you used for the eucledian distance again, but now using the pearson correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE 1:\n",
      "\n",
      "0.39605901719066977\n",
      "0.8660254037844378\n",
      "\n",
      "EXAMPLE 2:\n",
      "\n",
      "0.5345224838248488\n",
      "0.6324555320336759\n",
      "0.5547001962252291\n",
      "0.6666666666666666\n",
      "0.3651483716701107\n",
      "0.5163977794943222\n",
      "0.47140452079103173\n",
      "0.47140452079103173\n",
      "0.4\n",
      "0.7071067811865475\n",
      "0.6324555320336759\n",
      "0.4588314677411235\n",
      "0.6324555320336759\n",
      "1.1547005383792517\n",
      "0.8944271909999159\n"
     ]
    }
   ],
   "source": [
    "print(\"EXAMPLE 1:\\n\")\n",
    "\n",
    "print(sim_pearson('Lisa Rose','Gene Seymour'))\n",
    "print(sim_pearson('Amy','Lisa Rose'))\n",
    "\n",
    "\n",
    "print(\"\\nEXAMPLE 2:\\n\")\n",
    "\n",
    "people_cr = ['Lisa Rose', 'Michael Phillips', 'Claudia Puig', 'Mick LaSalle', 'Jack Matthews', 'Toby']\n",
    "\n",
    "for i in range(5,0,-1):\n",
    "    for e in range(len(people_cr)-1):\n",
    "        print(sim_distance(people_cr[i], people_cr[e], show_common_dims=False))\n",
    "\n",
    "    people_cr.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking critics on similarity\n",
    "The topMatches function below calculates all similarities of a given critic with his peers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topMatches(person, n=5, similarity=sim_pearson, prefs=critics):\n",
    "    '''\n",
    "    Returns the best matches for person from the prefs dictionary. \n",
    "    Number of results and similarity function are optional params.\n",
    "    '''\n",
    "    if similarity not in [sim_distance, sim_pearson]:\n",
    "        # NB: here we are comparing FUNCTION DEFINITION.\n",
    "        # We do that only in a jupyter notebook for the sake of simplicity.\n",
    "        raise ValueError(\"Callback functions should be: 'sim_pearson' or 'sim_distance'.\")\n",
    "        \n",
    "    scores = [(similarity(person, other, prefs=prefs), other) for other in prefs\n",
    "              if other != person]\n",
    "    scores.sort()\n",
    "    scores.reverse()\n",
    "    return scores[0:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can now get the 3 critics closest to Toby by calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 'Amy'),\n",
       " (0.9912407071619299, 'Lisa Rose'),\n",
       " (0.9244734516419049, 'Mick LaSalle')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topMatches('Toby',n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "### Task: Effect of similarity function used\n",
    "Call the topMatches function on a number of critics with both the default sim_pearson, but also with the sim_distance function. Would you have preference of one over the other? \n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toby:\n",
      "  Eucledian: [(2.0, 'Amy'), (0.6666666666666666, 'Mick LaSalle'), (0.6324555320336759, 'Michael Phillips'), (0.5547001962252291, 'Claudia Puig'), (0.5345224838248488, 'Lisa Rose')]\n",
      "  Pearson:   [(1.0, 'Amy'), (0.9912407071619299, 'Lisa Rose'), (0.9244734516419049, 'Mick LaSalle'), (0.8934051474415647, 'Claudia Puig'), (0.66284898035987, 'Jack Matthews')]\n",
      "\n",
      "Lisa Rose:\n",
      "  Eucledian: [(0.8944271909999159, 'Michael Phillips'), (0.7071067811865475, 'Mick LaSalle'), (0.6324555320336759, 'Claudia Puig'), (0.6030226891555273, 'Amy'), (0.5345224838248488, 'Toby')]\n",
      "  Pearson:   [(0.9912407071619299, 'Toby'), (0.8660254037844378, 'Amy'), (0.7470178808339965, 'Jack Matthews'), (0.5940885257860044, 'Mick LaSalle'), (0.5669467095138396, 'Claudia Puig')]\n",
      "\n",
      "Claudia Puig:\n",
      "  Eucledian: [(1.1547005383792517, 'Michael Phillips'), (0.6666666666666666, 'Amy'), (0.6324555320336759, 'Lisa Rose'), (0.5547001962252291, 'Toby'), (0.47140452079103173, 'Jack Matthews')]\n",
      "  Pearson:   [(1.0, 'Michael Phillips'), (0.8934051474415647, 'Toby'), (0.5669467095138411, 'Mick LaSalle'), (0.5669467095138396, 'Lisa Rose'), (0.31497039417435607, 'Gene Seymour')]\n",
      "\n",
      "Amy:\n",
      "  Eucledian: [(2.0, 'Toby'), (0.7071067811865475, 'Mick LaSalle'), (0.7071067811865475, 'Jack Matthews'), (0.6666666666666666, 'Claudia Puig'), (0.6030226891555273, 'Lisa Rose')]\n",
      "  Pearson:   [(1.0, 'Toby'), (0.8660254037844402, 'Mick LaSalle'), (0.8660254037844378, 'Lisa Rose'), (0.5, 'Michael Phillips'), (0.5, 'Jack Matthews')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Toby:\")\n",
    "print(f\"  Eucledian: {topMatches('Toby',n=5, similarity=sim_distance)}\")\n",
    "print(f\"  Pearson:   {topMatches('Toby',n=5)}\")\n",
    "\n",
    "print(\"\\nLisa Rose:\")\n",
    "print(f\"  Eucledian: {topMatches('Lisa Rose',n=5, similarity=sim_distance)}\")\n",
    "print(f\"  Pearson:   {topMatches('Lisa Rose',n=5)}\")\n",
    "\n",
    "print(\"\\nClaudia Puig:\")\n",
    "print(f\"  Eucledian: {topMatches('Claudia Puig',n=5, similarity=sim_distance)}\")\n",
    "print(f\"  Pearson:   {topMatches('Claudia Puig',n=5)}\")\n",
    "\n",
    "print(\"\\nAmy:\")\n",
    "print(f\"  Eucledian: {topMatches('Amy',n=5, similarity=sim_distance)}\")\n",
    "print(f\"  Pearson:   {topMatches('Amy',n=5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the Eucledian distance can only ever take positive values, thanks to the squared differences, this is not true for Pearsons measure: It relies on the standard deviation, which can be positive and negative. Consequently, they have to be interpreted differently. However, overall the Eucledian differance seems much simpler to translate into real world meaning. The Pearson correlation might measures a strong dependence, but this correlation may not necessarily translate into a similar taste/rating behaviour: This correlation could also be offset significantly, resulting in a large difference in the actual ratings.\n",
    "\n",
    "As a consequence, the Pearson measure is only interesting to identify similarities in rating behaviour relative to the mean of all ratings compared. However, if user A prefers comedy, and thus rates all horror movies badly, a user B, who only watched horror, might rate these movies significantly better, but still in a similar order relative to each other. In this case, the Pearson correlation between A and B would still be large, even though the ratings itself, and thus their taste is not.\n",
    "\n",
    "Depending on the requirements, either measure might be useful though: If we are interested in the quality rating of movies relative to each other, we would prefer the Pearson correlation. If we are interested in the actual ratings, and thus opinions of two users, then the Eucledian distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2: Recommending Items**\n",
    "\n",
    "One way to recommend movies to a person would be to rate the movies she has not seen yet by using the scores of the others weighted by the similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecommendations(person, similarity=sim_pearson, prefs=critics):\n",
    "    '''\n",
    "    Gets recommendations for a person by using a weighted average\n",
    "    of every other user's rankings\n",
    "    '''\n",
    "    if similarity not in [sim_distance, sim_pearson]:\n",
    "        raise ValueError(\"Callback functions should be: 'sim_pearson' or 'sim_distance'.\")\n",
    "\n",
    "    totals = {}\n",
    "    simSums = {}\n",
    "    for other in prefs:\n",
    "    # Don't compare me to myself\n",
    "        if other == person:\n",
    "            continue\n",
    "        sim = similarity(person, other, prefs=prefs)\n",
    "    # Ignore scores of zero or lower\n",
    "        if sim <= 0: \n",
    "            continue\n",
    "        for item in prefs[other]:\n",
    "            # Only score movies I haven't seen yet\n",
    "            if item not in prefs[person] or prefs[person][item] == 0:\n",
    "                # Similarity * Score\n",
    "                    totals.setdefault(item, 0)\n",
    "                    # The final score is calculated by multiplying each item by the\n",
    "                    #   similarity and adding these products together\n",
    "                    totals[item] += prefs[other][item] * sim\n",
    "                    # Sum of similarities\n",
    "                    simSums.setdefault(item, 0)\n",
    "                    simSums[item] += sim\n",
    "    # Create the normalized list\n",
    "    rankings = [(total / simSums[item], item) for (item, total) in\n",
    "                totals.items()]\n",
    "    # Return the sorted list\n",
    "    rankings.sort()\n",
    "    rankings.reverse()\n",
    "    return rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.4721701369256524, 'The Night Listener'),\n",
       " (2.8716745911876562, 'Lady in the Water'),\n",
       " (2.4349456273856207, 'Just My Luck')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getRecommendations('Toby', similarity=sim_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.3477895267131017, 'The Night Listener'),\n",
       " (2.8748373260264186, 'Lady in the Water'),\n",
       " (2.530980703765565, 'Just My Luck')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getRecommendations('Toby')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output does not only consist of a movie title, but also a guess at what the user's rating for each movie would be.\n",
    "\n",
    "*****************************************************\n",
    "### Task: Explainable recommendations\n",
    "Can you also find out how to give information on how the recommendation is built up. For example about the 'closest' person that also watched this movie?\n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task, we will extract the best recommendations, as well as the closest critic to a user. Now, we search for the movie with the highest recommendation, that is also rated by the closest critic. This movie is likely to fit to the user's taste, and we can advertise it as \"liked by your closest critic\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations based on your closest critic Amy:\n",
      "  -> Lady in the Water, rated 3.0 by them!\n"
     ]
    }
   ],
   "source": [
    "# Get the ratings for the recommended movies from the closest person\n",
    "ranking = getRecommendations('Toby')\n",
    "matches = topMatches('Toby')\n",
    "\n",
    "movies = [item for (rank, item) in ranking]\n",
    "close_critics = [critic for (rank, critic) in matches]\n",
    "\n",
    "closest_critic = critics[close_critics[0]]\n",
    "\n",
    "movies_closest_critic = closest_critic.keys()\n",
    "ratings_closest_critic = closest_critic.values()\n",
    "\n",
    "closest_critic_ratings = []\n",
    "\n",
    "for movie in movies:\n",
    "    if movie in movies_closest_critic:\n",
    "        closest_critic_ratings.append((movie, closest_critic[movie]))\n",
    "\n",
    "\n",
    "print(f'Recommendations based on your closest critic {close_critics[0]}:')\n",
    "for title, rating in closest_critic_ratings:\n",
    "    print(f'  -> {title}, rated {rating} by them!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 3: Transformations** \n",
    "**You have been building recommendations based on similar users in Exercise 2, but you could of course also build recommendations based on similar items. In this exercise you will do this.** \n",
    "\n",
    "The function is essentially the same, but you need to transfer your data, from:\n",
    "\n",
    "<code>{'Lisa Rose': {'Lady in the Water': 2.5, 'Snakes on a Plane': 3.5},\n",
    "'Gene Seymour': {'Lady in the Water': 3.0, 'Snakes on a Plane': 3.5}}</code>\n",
    "\n",
    "to\n",
    "\n",
    "<code>{'Lady in the Water': {'Lisa Rose': 2.5,'Gene Seymour': 3.0},\n",
    "'Snakes on a Plane': {'Lisa Rose': 3.5,'Gene Seymour': 3.5}}</code>\n",
    "\n",
    "This is what the transformPrefs function does. \n",
    "\n",
    "You can now create a dictionary for movies with their scores assigned by different people by invoking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformPrefs(prefs=critics):\n",
    "    '''\n",
    "    Transform the recommendations into a mapping where persons are described\n",
    "    with interest scores for a given title e.g. {title: person} instead of\n",
    "    {person: title}.\n",
    "    '''\n",
    "    result = {}\n",
    "    for person in prefs:\n",
    "        for item in prefs[person]:\n",
    "            result.setdefault(item, {})\n",
    "            # Flip item and person\n",
    "            result[item][person] = prefs[person][item]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lady in the Water': {'Lisa Rose': 2.5, 'Gene Seymour': 3.0, 'Michael Phillips': 2.5, 'Mick LaSalle': 3.0, 'Jack Matthews': 3.0, 'Amy': 3.0}, 'Snakes on a Plane': {'Lisa Rose': 3.5, 'Gene Seymour': 3.5, 'Michael Phillips': 3.0, 'Claudia Puig': 3.5, 'Mick LaSalle': 4.0, 'Jack Matthews': 4.0, 'Toby': 4.5, 'Amy': 5.0}, 'Just My Luck': {'Lisa Rose': 3.0, 'Gene Seymour': 1.5, 'Claudia Puig': 3.0, 'Mick LaSalle': 2.0}, 'Superman Returns': {'Lisa Rose': 3.5, 'Gene Seymour': 5.0, 'Michael Phillips': 3.5, 'Claudia Puig': 4.0, 'Mick LaSalle': 3.0, 'Jack Matthews': 5.0, 'Toby': 4.0, 'Amy': 4.0}, 'You, Me and Dupree': {'Lisa Rose': 2.5, 'Gene Seymour': 3.5, 'Claudia Puig': 2.5, 'Mick LaSalle': 2.0, 'Jack Matthews': 3.5, 'Toby': 1.0}, 'The Night Listener': {'Lisa Rose': 3.0, 'Gene Seymour': 3.0, 'Michael Phillips': 4.0, 'Claudia Puig': 4.5, 'Mick LaSalle': 3.0, 'Jack Matthews': 3.0}}\n"
     ]
    }
   ],
   "source": [
    "movies = transformPrefs()\n",
    "print(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And find similar items for a particular movie like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6579516949597695, 'You, Me and Dupree'),\n",
       " (0.46291004988627404, 'Lady in the Water'),\n",
       " (0.07881104062391006, 'Snakes on a Plane'),\n",
       " (-0.1798471947990544, 'The Night Listener'),\n",
       " (-0.42289003161103106, 'Just My Luck')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topMatches('Superman Returns', prefs=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or find people who may like a particular movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4.0, 'Michael Phillips'), (3.0, 'Jack Matthews')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getRecommendations('Just My Luck', prefs=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "#### Task: why does the example above work?\n",
    "Try to follow exactly what is going on in the last call. Notice that Michael and Jack did not rate 'Just my Luck'. How is their rating for it built up?\n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of calculating which movies would fit to an input user, we start with a movie. For this input movie, we check how similar each other movie is. Now, we can test how each user rated these movies. We sum up all these ratings for each user, weighted by the similarity a movie has to the input movie. This way, ratings for movies more similar to the input movie have a stronger impact on the final result, as it is more likely that those ratings can be translate to the input movie.\n",
    "\n",
    "The result is a dictionary, mapping for each user how they would likely rate the input movie. By sorting these according to the predicted rating, we get the users that are most likely to like the input movie. All resulting users will hereby not have watched the movie yet, as we filter out those users previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 4: Sentence Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import natural language processing software we need later.\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Maximilian\n",
      "[nltk_data]     Mayer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Maximilian\n",
      "[nltk_data]     Mayer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Maximilian\n",
      "[nltk_data]     Mayer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download wordnet and punkt sentence tokenizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have some example sentences to compare later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = [\"I saw a really good movie last night.\",\n",
    "\"The movie is based on the director's life.\",\n",
    "\"The movie starts at ten.\",\n",
    "\"I took her to a movie.\",\n",
    "\"The movie stars Al Pacino.\",\n",
    "\"The movie opened last weekend.\",\n",
    "\"The movie lasted two hours.\",\n",
    "\"He directed several movies.\", \n",
    "\"We just shot another movie.\", \n",
    "\"The movie was set in New York.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard_sim(str1, str2): \n",
    "    a = set(str1.split()) \n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the Jaccard Similarity of two sentences however, we first need to do some preprocessing in the form of Lemmatization and Tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(s1, s2):\n",
    "\n",
    "    #Import a Lemmatizer to get the root form of certain words\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    \n",
    "    #Tokenize both sentences to get each word separately\n",
    "    word_list1 = nltk.word_tokenize(s1)\n",
    "    word_list2 = nltk.word_tokenize(s2)\n",
    "    \n",
    "#     print(\"Tokenized sentence\", word_list1) #Uncomment to see an example of the tokenized sentence \n",
    "    \n",
    "    #Lemmatize both sentences\n",
    "    lemmatized_output1 = ' '.join([lemmatizer.lemmatize(w, 'v') for w in word_list1])\n",
    "    lemmatized_output2 = ' '.join([lemmatizer.lemmatize(w, 'v') for w in word_list2])\n",
    "    \n",
    "    return lemmatized_output1, lemmatized_output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: I saw a really good movie last night . \n",
      " Similarity Score: 1.0 \n",
      "\n",
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: The movie be base on the director 's life . \n",
      " Similarity Score: 0.11764705882352941 \n",
      "\n",
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: The movie start at ten . \n",
      " Similarity Score: 0.15384615384615385 \n",
      "\n",
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: I take her to a movie . \n",
      " Similarity Score: 0.3333333333333333 \n",
      "\n",
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: The movie star Al Pacino . \n",
      " Similarity Score: 0.15384615384615385 \n",
      "\n",
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: The movie open last weekend . \n",
      " Similarity Score: 0.25 \n",
      "\n",
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: The movie last two hours . \n",
      " Similarity Score: 0.25 \n",
      "\n",
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: He direct several movies . \n",
      " Similarity Score: 0.07692307692307693 \n",
      "\n",
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: We just shoot another movie . \n",
      " Similarity Score: 0.15384615384615385 \n",
      "\n",
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: The movie be set in New York . \n",
      " Similarity Score: 0.13333333333333333 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "for x in range(len(movies)):\n",
    "    l1, l2 = compare(movies[0], movies[x])\n",
    "    print(\"Sentence 1:\", l1, '\\n', \"Sentence 2:\", l2, '\\n', \"Similarity Score:\", get_jaccard_sim(l1,l2), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "#### Task: In what scenario's could the Jaccard Similarity be more useful than the Euclidean distance and the Pearson Similarity metrics? Why is that? \n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of movie recommendations, the Jaccard Similarity could be used to recommend movies with similar titles, or, if a description of the movie is available, movies with a similar description. Alternatively, it could be used to recommend movies based on a given query. A critic could, for example, provide a number of words they would like to see in a movie's description, and the movie with the greatest similarity between description and these search terms could be recommended.\n",
    "\n",
    "In more general terms, it is hard to compare the Eucledian distance or the Pearson Similarity to the Jaccard Similarity, as the latter operates on words, while the other two use numbers. Consequently, every recommendation or comparison of text, sentences, or words would require the Jaccard Similarity. However, in turn it would be rather useless, or at least complicated to use in combination with ratings, as we did previously.\n",
    "\n",
    "In conclusion, while all three methods calculate some form of similarity, they are designed for very different contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 5: Building a Reddit Recommender**\n",
    "\n",
    "After having created your Reddit account, go to User Settings -> Safety & Privacy -> Manage third-party app authorization.\n",
    "Here, you will create your own app. Give it a name, and add \"https://www.reddit.com/prefs/apps/\" to the redirect uri. Keep the other settings as they are.\n",
    "You may encounter some issues accessing \"https://www.reddit.com/prefs/apps/\" in Chrome. If so, try with another browser.\n",
    "\n",
    "* replace the '???' in the user_agent string with your name (or any unique string).\n",
    "* replace the '???' in the client_id with the id right underneath your web app name.\n",
    "* replace the '???' in the client_secret with the key next to 'secret'.\n",
    "\n",
    "NOTE: install praw v. 3.5 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import praw\n",
    "import time\n",
    "\n",
    "#Delete keys before handing in the notebook\n",
    "r = praw.Reddit(user_agent='xantocxx', \n",
    "                client_id='HRlw289OL306ni3U-w3Cng',\n",
    "                client_secret='SVoSSTOpaZirKGTUmgBILs7HpTbXTw',\n",
    "                redirect_url='https://www.reddit.com/prefs/apps/'\n",
    "                             'authorize_callback')\n",
    "\n",
    "\n",
    "def initializeUserDict(subreddit, count=10):\n",
    "    user_dict={}\n",
    "    # get the top count' popular posts\n",
    "    for post in r.subreddit(subreddit).top(limit=count):\n",
    "        # find all users who commented in this\n",
    "        flat_comments = post.comments.list()\n",
    "        for comment in flat_comments:\n",
    "            try:\n",
    "                user = comment.author.name\n",
    "                user_dict[user] = {}\n",
    "            except AttributeError:\n",
    "                pass\n",
    "    return user_dict\n",
    "\n",
    "def fillItems(user_dict, count=100):\n",
    "    all_items={}\n",
    "    # Find links posted by all users\n",
    "    for user in user_dict:\n",
    "        # print(\"finding subreddits where user \" + user + \"has commented\")\n",
    "        # find new comments for given user\n",
    "        comments = r.redditor(user).comments.new(limit=count)\n",
    "        for c in comments:\n",
    "            # Get the subreddit where the comment was made\n",
    "            subreddit = c.subreddit\n",
    "            sub_name = subreddit.display_name\n",
    "            # print(sub_name)\n",
    "            if sub_name in user_dict[user]:\n",
    "                user_dict[user][sub_name] += 1.0\n",
    "            else:\n",
    "                user_dict[user][sub_name] = 1.0\n",
    "            \n",
    "            all_items[sub_name] = 1\n",
    "#     Fill in missing items with 0\n",
    "#     for subr_counts in user_dict.values():\n",
    "#         for item in all_items:\n",
    "#             if item not in subr_counts:\n",
    "#                 subr_counts[item]=0.0\n",
    "    \n",
    "    return user_dict\n",
    "\n",
    "def fillComments(user_dict, count=100):\n",
    "    all_items={}\n",
    "    # Find links posted by all users\n",
    "    for user in user_dict:\n",
    "        # print(\"finding subreddits where user \" + user + \"has commented\")\n",
    "        # find new comments for given user\n",
    "        comments = r.redditor(user).comments.new(limit=count)\n",
    "        for c in comments:\n",
    "            # Get the subreddit where the comment was made\n",
    "            post = c.submission\n",
    "            post_name = post.name\n",
    "            # print(sub_name)\n",
    "            if post_name in user_dict[user]:\n",
    "                user_dict[user][post_name] += 1.0\n",
    "            else:\n",
    "                user_dict[user][post_name] = 1.0\n",
    "            \n",
    "            all_items[post_name] = 1\n",
    "#     Fill in missing items with 0\n",
    "#     for subr_counts in user_dict.values():\n",
    "#         for item in all_items:\n",
    "#             if item not in subr_counts:\n",
    "#                 subr_counts[item]=0.0\n",
    "    \n",
    "    return user_dict\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a list of popular recent posts about programming from the programming subreddit (https://www.reddit.com/r/VUAmsterdam) by invoking the code below.  Don't forget to replace the '???' in the user_agent string with your name (or any unique string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "praw version == 7.6.1\n",
      "\n",
      " * Opinions on Political Science: Global Politics\n",
      "\n",
      " * Menta Health Well-being at the VU\n",
      "\n",
      " * Coronavirus at the VU\n",
      "\n",
      " * Got accepted into cs program last year, but now it’s numerous fixus\n",
      "\n",
      " * Improving the subreddit\n"
     ]
    }
   ],
   "source": [
    "print(\"praw version == \" + praw.__version__)\n",
    "\n",
    "# subreddit = r.subreddit(\"programming\")\n",
    "for post in r.subreddit('VUAmsterdam').top(limit=5):\n",
    "     print(end='\\n * ')\n",
    "     print(post.title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See here a list of other subreddits you can explore with this code: https://www.reddit.com/reddits/\n",
    "\n",
    "To automatically create a data set of reddit users similar to the movie watchers you can invoke the initializeUserDict function in redditrec.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Digesta94': {}, 'CrazyRide72': {}, 'SenseiTrade': {}, 'BillHoudini': {}, 'angulardragon03': {}, '-BYeBYe-': {}, 'visvis': {}, 'samsungebluckburry': {}, 'PlantBeanVibes': {}, 'schuifdurrrr': {}, 'reks_rb': {}, 'No-Trip-3464': {}, 'Any_Watercress7798': {}, 'cariimejia16': {}, 'ElkNo1598': {}, 'Adorable_Suggestion4': {}, 'PawBud': {}, 'DomDom2002': {}, 'aitahb': {}, 'DigProgrammatically3': {}, 'aythida': {}, 'rexygorl': {}, 'redmehalis': {}, 'Otherwise_Extreme_59': {}, 'wassup5551': {}, 'deepshitgoeshere': {}, 'These-Psychology-959': {}, 'macedoineGontran': {}, 'Thenextelonmusklol': {}, 'nfp267': {}, 'amaxs': {}, 'ImAClosetNerd': {}, 'Agreeable_Baseball87': {}, 'whocares4817': {}, 'Administrative_Fun_6': {}}\n"
     ]
    }
   ],
   "source": [
    "red_users=initializeUserDict('VUAmsterdam', count=15) # or for any other subreddit\n",
    "print(red_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now initializeUserDict has only created the user keys. We of course also want to know what subreddits they posted comments on. You can pull those in through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Digesta94': {'VUAmsterdam': 1.0},\n",
       " 'CrazyRide72': {'StudyInTheNetherlands': 9.0,\n",
       "  'VUAmsterdam': 3.0,\n",
       "  'Denmark': 1.0,\n",
       "  'Advice': 1.0,\n",
       "  'MDMA': 1.0},\n",
       " 'SenseiTrade': {'VUAmsterdam': 2.0,\n",
       "  'FreeKarma4You': 1.0,\n",
       "  'FitnessMaterialHeaven': 1.0,\n",
       "  'AskReddit': 2.0,\n",
       "  'overcominggravity': 3.0,\n",
       "  'LifeProTips': 1.0,\n",
       "  'bodyweightfitness': 1.0,\n",
       "  'powerlifting': 2.0,\n",
       "  'weightlifting': 2.0},\n",
       " 'BillHoudini': {'tennis': 7.0,\n",
       "  'europe': 1.0,\n",
       "  'TechnoProduction': 1.0,\n",
       "  'soccer': 1.0,\n",
       "  'progmetal': 1.0,\n",
       "  'DunderMifflin': 1.0,\n",
       "  'footballmanagergames': 1.0,\n",
       "  'Barca': 1.0,\n",
       "  'Beatmatch': 1.0},\n",
       " 'angulardragon03': {'VUAmsterdam': 10.0,\n",
       "  'StudyInTheNetherlands': 1.0,\n",
       "  'swift': 2.0,\n",
       "  'apple': 1.0,\n",
       "  'technology': 1.0},\n",
       " '-BYeBYe-': {'Windows10': 1.0,\n",
       "  'Liverpool': 4.0,\n",
       "  'Pixel6': 1.0,\n",
       "  'AskReddit': 6.0,\n",
       "  'VUAmsterdam': 1.0,\n",
       "  'JoblessReincarnation': 1.0,\n",
       "  'Minecraft': 1.0},\n",
       " 'visvis': {'thenetherlands': 9.0,\n",
       "  'StudyInTheNetherlands': 3.0,\n",
       "  'Music': 2.0,\n",
       "  'europe': 1.0},\n",
       " 'samsungebluckburry': {'GamingLeaksAndRumours': 1.0,\n",
       "  'IBO': 8.0,\n",
       "  'football': 1.0,\n",
       "  'Nepal': 2.0,\n",
       "  'VUAmsterdam': 1.0,\n",
       "  'nextfuckinglevel': 1.0,\n",
       "  'ksi': 1.0},\n",
       " 'PlantBeanVibes': {'VUAmsterdam': 13.0, 'redditgetsdrawn': 2.0},\n",
       " 'schuifdurrrr': {'TheWeeknd': 1.0,\n",
       "  'ukdrill': 5.0,\n",
       "  'AmItheAsshole': 1.0,\n",
       "  'Tekken7': 1.0,\n",
       "  'Tekken': 1.0,\n",
       "  'getdisciplined': 1.0,\n",
       "  'Calfmuscle': 1.0,\n",
       "  'csMajors': 2.0,\n",
       "  'VUAmsterdam': 1.0,\n",
       "  'NarcoFootage': 1.0},\n",
       " 'reks_rb': {'VUAmsterdam': 5.0,\n",
       "  'AskReddit': 1.0,\n",
       "  'StudyInTheNetherlands': 5.0,\n",
       "  'TUe': 2.0},\n",
       " 'No-Trip-3464': {'Amsterdam': 1.0,\n",
       "  'tressless': 1.0,\n",
       "  'teenagers': 2.0,\n",
       "  'VUAmsterdam': 3.0,\n",
       "  'AskReddit': 1.0,\n",
       "  'Drugs': 3.0,\n",
       "  'GREEK': 1.0,\n",
       "  'skiing': 2.0},\n",
       " 'Any_Watercress7798': {'AmsterdamEnts': 14.0, 'Amsterdam': 1.0},\n",
       " 'cariimejia16': {'StudyInTheNetherlands': 7.0,\n",
       "  'VUAmsterdam': 3.0,\n",
       "  'Amsterdam': 5.0},\n",
       " 'ElkNo1598': {'StudyInTheNetherlands': 1.0,\n",
       "  'VUAmsterdam': 1.0,\n",
       "  'learnpython': 10.0,\n",
       "  'learnprogramming': 2.0},\n",
       " 'Adorable_Suggestion4': {'queensuniversity': 5.0,\n",
       "  'VUAmsterdam': 1.0,\n",
       "  'TilburgUniversity': 2.0,\n",
       "  'uErasmus': 1.0},\n",
       " 'PawBud': {'Beatmatch': 1.0,\n",
       "  'shitposting': 1.0,\n",
       "  'StudyInTheNetherlands': 2.0,\n",
       "  'hyderabad': 1.0,\n",
       "  'VUAmsterdam': 4.0,\n",
       "  'Hardwell': 1.0,\n",
       "  'avicii': 1.0,\n",
       "  'facepalm': 1.0,\n",
       "  'developersIndia': 1.0,\n",
       "  'applehelp': 1.0,\n",
       "  'interestingasfuck': 1.0},\n",
       " 'DomDom2002': {'firstimpression': 1.0,\n",
       "  'Nike': 2.0,\n",
       "  'RunningShoeGeeks': 3.0,\n",
       "  'VUAmsterdam': 5.0,\n",
       "  'college': 1.0,\n",
       "  'StudyInTheNetherlands': 3.0},\n",
       " 'aitahb': {'PostgreSQL': 1.0,\n",
       "  'nginx': 1.0,\n",
       "  'django': 1.0,\n",
       "  'sysadmin': 1.0,\n",
       "  'universityofamsterdam': 1.0,\n",
       "  'VUAmsterdam': 3.0,\n",
       "  'gradadmissions': 1.0,\n",
       "  'tumunich': 6.0},\n",
       " 'DigProgrammatically3': {'celebJObuds': 1.0,\n",
       "  'Unexpected': 1.0,\n",
       "  'VUAmsterdam': 4.0,\n",
       "  'bangalore': 1.0,\n",
       "  'Netherlands': 3.0,\n",
       "  'gradadmissions': 1.0},\n",
       " 'aythida': {'VUAmsterdam': 2.0,\n",
       "  'bangalore': 2.0,\n",
       "  'dating_advice': 1.0,\n",
       "  'GYM': 1.0,\n",
       "  'BeAmazed': 1.0},\n",
       " 'rexygorl': {'bioinformatics': 2.0,\n",
       "  'stillwoozy': 9.0,\n",
       "  'seinfeld': 1.0,\n",
       "  'Amsterdam': 1.0,\n",
       "  'VUAmsterdam': 1.0,\n",
       "  'CageTheElephant': 1.0},\n",
       " 'redmehalis': {'VUAmsterdam': 1.0,\n",
       "  'Wizard101': 1.0,\n",
       "  'bigdickproblems': 1.0,\n",
       "  'greece': 2.0,\n",
       "  'AskBalkans': 8.0,\n",
       "  'mkd': 2.0},\n",
       " 'Otherwise_Extreme_59': {'StudyInTheNetherlands': 2.0, 'VUAmsterdam': 1.0},\n",
       " 'wassup5551': {'VUAmsterdam': 1.0,\n",
       "  'Laptop': 1.0,\n",
       "  'NoFap': 3.0,\n",
       "  'StudyInTheNetherlands': 4.0,\n",
       "  'Kanye': 4.0,\n",
       "  'HealthAnxiety': 1.0,\n",
       "  'AskReddit': 1.0},\n",
       " 'deepshitgoeshere': {'VUAmsterdam': 1.0,\n",
       "  'Amsterdam': 1.0,\n",
       "  'cscareerquestionsEU': 1.0,\n",
       "  'thinkpad': 3.0,\n",
       "  'LineageOS': 1.0,\n",
       "  'MechanicalKeyboards': 1.0,\n",
       "  'brockhampton': 1.0,\n",
       "  'Pizza': 2.0,\n",
       "  'todayilearned': 1.0,\n",
       "  'AskReddit': 1.0,\n",
       "  'bicycling': 2.0},\n",
       " 'These-Psychology-959': {'TUe': 3.0,\n",
       "  'StudyInTheNetherlands': 5.0,\n",
       "  'VUAmsterdam': 1.0,\n",
       "  'TUDelft': 2.0,\n",
       "  'space': 1.0,\n",
       "  'Futurology': 1.0},\n",
       " 'macedoineGontran': {'symfony': 1.0,\n",
       "  'ionic': 1.0,\n",
       "  'kde': 4.0,\n",
       "  'artixlinux': 3.0,\n",
       "  'cybersecurity_help': 1.0,\n",
       "  'vuejs': 2.0,\n",
       "  'VUAmsterdam': 1.0,\n",
       "  'fossdroid': 2.0},\n",
       " 'Thenextelonmusklol': {'universityofamsterdam': 1.0,\n",
       "  'IBO': 2.0,\n",
       "  'VUAmsterdam': 3.0,\n",
       "  'utwente': 5.0,\n",
       "  'StudyInTheNetherlands': 4.0},\n",
       " 'nfp267': {'VUAmsterdam': 2.0,\n",
       "  'sad': 4.0,\n",
       "  'Needafriend': 7.0,\n",
       "  'LGBTeens': 1.0,\n",
       "  'dating': 1.0},\n",
       " 'amaxs': {'CollegeTransfer': 2.0,\n",
       "  'PhD': 3.0,\n",
       "  'IWantOut': 3.0,\n",
       "  'PoliticalScience': 3.0,\n",
       "  'SocialNetworkAnalysis': 1.0,\n",
       "  'dataisbeautiful': 1.0,\n",
       "  'Coffee': 1.0,\n",
       "  'expats': 1.0},\n",
       " 'ImAClosetNerd': {'GalaxyS8': 1.0,\n",
       "  'samsung': 1.0,\n",
       "  'catsonglass': 1.0,\n",
       "  'movies': 2.0,\n",
       "  'Unexpected': 1.0,\n",
       "  'jellybeantoes': 1.0,\n",
       "  'misophonia': 2.0,\n",
       "  'Lenovo': 2.0,\n",
       "  'sony': 3.0,\n",
       "  'adhd_college': 1.0},\n",
       " 'Agreeable_Baseball87': {'StudyInTheNetherlands': 11.0,\n",
       "  'Netherlands': 1.0,\n",
       "  'unimelb': 3.0},\n",
       " 'whocares4817': {'KingkillerChronicle': 1.0,\n",
       "  'rickandmorty': 2.0,\n",
       "  'adventuretime': 6.0,\n",
       "  'TheLastAirbender': 1.0,\n",
       "  'regularshow': 2.0,\n",
       "  'movies': 1.0,\n",
       "  'todayilearned': 1.0,\n",
       "  'marvelmemes': 1.0},\n",
       " 'Administrative_Fun_6': {'Amsterdam': 1.0, 'VUAmsterdam': 2.0}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fillItems(red_users, count=15)\n",
    "# here you can see how often each user commented in what sub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script may take a few minutes to collect all the data. Use this time to review what is going on in the code. Notice that users don't give ratings to subreddits, instead we are counting how many comments they posted in each subreddit. \n",
    "\n",
    "To recommend a similar user, we can use our topMatches function again.\n",
    "\n",
    "First choose a random user for whom you're going to find neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No-Trip-3464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1.0, 'reks_rb'),\n",
       " (1.0, 'Administrative_Fun_6'),\n",
       " (0, 'whocares4817'),\n",
       " (0, 'wassup5551'),\n",
       " (0, 'visvis')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "user= random.choice( list( red_users.keys() ))\n",
    "print (user) # print the username \n",
    "topMatches(user, prefs=red_users) # from all redditors, get the most similar to user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no similar user was found, you can try increasing the count of users or comments for each initializeUserDict and fillItems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "#### Task: Recommend subreddits for a user based on what subreddits similar users have commented in. Recommend posts for a user based on posts they have commented on. \n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def socialRecommendations(chosen_user, user_items, max_number=5):\n",
    "    # from all redditors, get the most similar to user\n",
    "    # we use pearson similarity, as we do not care about the overall number of comments made, but a general trend of similarity\n",
    "    similar_users = {user: similarity for similarity, user in topMatches(chosen_user, n=5, prefs=user_items)}\n",
    "\n",
    "    # get bes subreddit recommendations based on other users' preferences\n",
    "    best_subreddits = {subreddit: rating for rating, subreddit in getRecommendations(chosen_user, prefs=user_items)}\n",
    "\n",
    "    print(f\"Selected User:\\n{chosen_user}\\n\")\n",
    "    print(f\"Similar Users:\\n{similar_users}\\n\")\n",
    "    print(f\"Most Fitting Items based on other Users' Preferences:\\n{best_subreddits}\\n\")\n",
    "\n",
    "    # find all subreddits used by similar users and check how much they would fit for our user based on their similarity to that user\n",
    "    recommended_subreddits = {}\n",
    "    for user, similarity in similar_users.items():\n",
    "        for subreddit, rating in user_items[user].items():\n",
    "            if subreddit in user_items[chosen_user]: continue\n",
    "            recommended_subreddits.setdefault(subreddit, 0)\n",
    "            recommended_subreddits[subreddit] += similarity * rating\n",
    "\n",
    "    # sort recommendations\n",
    "    recommended_subreddits = dict(reversed(sorted(recommended_subreddits.items(), key=lambda item: item[1])))\n",
    "\n",
    "    print(f\"Recommended Items based on Similar Users:\\n{recommended_subreddits}\\n\")\n",
    "\n",
    "    # list of all subreddits that may be recommended\n",
    "    all_recommended_subreddits = set(list(best_subreddits.keys()) + list(recommended_subreddits.keys()))\n",
    "\n",
    "    # merge both recommendations\n",
    "    final_recommendations = {}\n",
    "    for subreddit in all_recommended_subreddits:\n",
    "        best_subreddits.setdefault(subreddit, 0)\n",
    "        recommended_subreddits.setdefault(subreddit, 0)\n",
    "\n",
    "        # We weight the best_recommendations higher, as they are the optimal recommendations for this user, while recommended_subreddits only contains the best options\n",
    "        # that were found within the list of similar users. However, that list may contain multiple users with similarity 0, and is thus not as reliable.\n",
    "        final_recommendations[subreddit] = (3 * best_subreddits[subreddit] + 2 * recommended_subreddits[subreddit]) / 5\n",
    "\n",
    "    # sort recommendations and limit to top 5\n",
    "    recommendation_count = min(max_number, len(final_recommendations))\n",
    "    final_recommendations = dict(list(reversed(sorted(final_recommendations.items(), key=lambda item: item[1])))[:recommendation_count])\n",
    "\n",
    "    print(f\"Best Combined Recommendation:\\n{final_recommendations}\")\n",
    "\n",
    "    return final_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected User:\n",
      "Thenextelonmusklol\n",
      "\n",
      "Similar Users:\n",
      "{'wassup5551': 1.0, 'cariimejia16': 1.0, 'aitahb': 1.0, 'These-Psychology-959': 1.0, 'Otherwise_Extreme_59': 1.0}\n",
      "\n",
      "Most Fitting Items based on other Users' Preferences:\n",
      "{'tumunich': 6.0, 'Amsterdam': 5.0, 'Kanye': 4.0, 'TUe': 3.0, 'NoFap': 3.0, 'TUDelft': 2.0, 'sysadmin': 1.0, 'space': 1.0, 'nginx': 1.0, 'gradadmissions': 1.0, 'django': 1.0, 'PostgreSQL': 1.0, 'MDMA': 1.0, 'Laptop': 1.0, 'HealthAnxiety': 1.0, 'Futurology': 1.0, 'Denmark': 1.0, 'AskReddit': 1.0, 'Advice': 1.0}\n",
      "\n",
      "Recommended Items based on Similar Users:\n",
      "{'tumunich': 6.0, 'Amsterdam': 5.0, 'Kanye': 4.0, 'TUe': 3.0, 'NoFap': 3.0, 'TUDelft': 2.0, 'Futurology': 1.0, 'space': 1.0, 'gradadmissions': 1.0, 'sysadmin': 1.0, 'django': 1.0, 'nginx': 1.0, 'PostgreSQL': 1.0, 'AskReddit': 1.0, 'HealthAnxiety': 1.0, 'Laptop': 1.0}\n",
      "\n",
      "Best Combined Recommendation:\n",
      "{'tumunich': 6.0, 'Amsterdam': 5.0, 'Kanye': 4.0, 'NoFap': 3.0, 'TUe': 3.0}\n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "\n",
    "# BEST SUBREDDITS RECOMMENDATION\n",
    "\n",
    "# setup users array with data\n",
    "OVERWRITE = False\n",
    "if red_users is None or OVERWRITE:\n",
    "    users = initializeUserDict('VUAmsterdam', count=30) \n",
    "    fillItems(users, count=30)\n",
    "else:\n",
    "    users = red_users\n",
    "\n",
    "# choose user with at least one other similar user(s) with similarity > 0\n",
    "# this is not necessary, but ensures that we can make any recommendations based on preference using the getRecommendations method, and is thus more interesting\n",
    "while True:\n",
    "\n",
    "    # select random user\n",
    "    chosen_user = choice(list(users.keys()))\n",
    "\n",
    "    # from all redditors, get the most similar to user\n",
    "    # we use pearson similarity, as we do not care about the overall number of comments made, but a general trend of similarity\n",
    "    similar_users = {user: similarity for similarity, user in topMatches(chosen_user, n=5, prefs=users)}\n",
    "\n",
    "    # check if any similarity value to the found users is larger than 0\n",
    "    if any(similarity > 0 for similarity in similar_users.values()):\n",
    "        break\n",
    "\n",
    "recommendations = socialRecommendations(chosen_user, users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Digesta94': {'t3_yfohi6': 1.0}, 'CrazyRide72': {'t3_yvznih': 2.0, 't3_yvr3so': 1.0, 't3_yflph6': 1.0, 't3_yfohi6': 2.0, 't3_yepjzg': 7.0, 't3_y3qitw': 1.0, 't3_xfx6c4': 1.0}, 'SenseiTrade': {'t3_yfohi6': 1.0, 't3_xfvx2w': 1.0, 't3_ugu62f': 1.0, 't3_wqrimu': 1.0, 't3_wkdua9': 1.0, 't3_whyrub': 1.0, 't3_w8i9kw': 1.0, 't3_w2p2dm': 1.0, 't3_t70amu': 1.0, 't3_sz2hr9': 1.0, 't3_sthcx5': 1.0, 't3_mv1rn0': 2.0, 't3_pf9mi6': 2.0}, 'BillHoudini': {'t3_z1bd2t': 1.0, 't3_z0cgcd': 1.0, 't3_ys1ge2': 1.0, 't3_y6hbb8': 1.0, 't3_y5mi3k': 1.0, 't3_xzvvt7': 1.0, 't3_xt4tzt': 1.0, 't3_xrqzm7': 1.0, 't3_xpe2gh': 1.0, 't3_xnv7gp': 1.0, 't3_xlhmdv': 2.0, 't3_xjex9m': 1.0, 't3_xewl7n': 1.0, 't3_x7h3j3': 1.0}, 'angulardragon03': {'t3_z0wcf0': 1.0, 't3_yvpwaf': 1.0, 't3_y7n5ci': 1.0, 't3_y1z3ya': 1.0, 't3_xw6lan': 2.0, 't3_xtsjm6': 1.0, 't3_xg4c8t': 2.0, 't3_x79pz4': 3.0, 't3_x8wkae': 1.0, 't3_w5z1ro': 1.0, 't3_wwm5en': 1.0}, '-BYeBYe-': {'t3_z3nc13': 1.0, 't3_w2oqpf': 2.0, 't3_w1qiw4': 1.0, 't3_w0o5n7': 1.0, 't3_vy4lzz': 2.0, 't3_vvpcwa': 1.0, 't3_v1p1ew': 1.0, 't3_usxlc5': 1.0, 't3_upaz89': 1.0, 't3_uda8sq': 1.0, 't3_uagwv9': 1.0, 't3_uae7oi': 1.0, 't3_u6z3fj': 1.0}, 'visvis': {'t3_zbkktr': 1.0, 't3_zbllf3': 1.0, 't3_zbdhat': 8.0, 't3_zbjbpq': 1.0, 't3_zbfjo7': 1.0, 't3_zb0uqh': 1.0, 't3_zbblyx': 1.0, 't3_zae95r': 1.0}, 'samsungebluckburry': {'t3_woefl8': 1.0, 't3_x7zpt6': 1.0, 't3_x3tvkw': 1.0, 't3_x3f7th': 1.0, 't3_wwhmvf': 1.0, 't3_wrfp81': 1.0, 't3_wr69gs': 1.0, 't3_wqnliu': 1.0, 't3_wrc19a': 1.0, 't3_wra48h': 1.0, 't3_wqu19e': 1.0, 't3_woo8y9': 1.0, 't3_wozwp6': 1.0, 't3_wk3v24': 1.0, 't3_wioy83': 1.0}, 'PlantBeanVibes': {'t3_x73x8v': 1.0, 't3_vvpcwa': 1.0, 't3_x0v7rc': 1.0, 't3_vqy4i1': 1.0, 't3_vujtaj': 1.0, 't3_w1ylml': 1.0, 't3_s6eff5': 1.0, 't3_ryq10w': 1.0, 't3_r8gu01': 1.0, 't3_qve8hr': 1.0, 't3_o4hg1r': 1.0, 't3_mvnx26': 1.0, 't3_jvjsjx': 1.0, 't3_jj0w84': 1.0, 't3_j3c4hu': 1.0}, 'schuifdurrrr': {'t3_z8qvwn': 1.0, 't3_yp00cx': 2.0, 't3_yob4h6': 1.0, 't3_yoyrzo': 1.0, 't3_ybsmjf': 1.0, 't3_x7z2us': 1.0, 't3_y47utx': 1.0, 't3_x36dby': 1.0, 't3_xnyfcm': 1.0, 't3_xh3c37': 1.0, 't3_vmi2r0': 1.0, 't3_u9x47q': 1.0, 't3_u2zfdh': 1.0, 't3_tp3n4w': 1.0}, 'reks_rb': {'t3_vmi2r0': 1.0, 't3_u4563b': 1.0, 't3_ui4z05': 1.0, 't3_v8uxiw': 1.0, 't3_isyk53': 1.0, 't3_iazsu8': 2.0, 't3_gyylzl': 1.0, 't3_gxwk04': 1.0, 't3_g35ri2': 3.0, 't3_g41vry': 1.0}, 'No-Trip-3464': {'t3_z5w24x': 1.0, 't3_yiq7c7': 1.0, 't3_wcjdv2': 1.0, 't3_vejubw': 1.0, 't3_vap0pf': 1.0, 't3_v5kkhf': 1.0, 't3_rqna7u': 1.0, 't3_r526ca': 1.0, 't3_r2vabj': 1.0, 't3_quqcdz': 1.0, 't3_qtvvwj': 1.0, 't3_qrxn3d': 1.0, 't3_nz1yo6': 2.0}, 'Any_Watercress7798': {'t3_z66q0i': 8.0, 't3_z6ttro': 3.0, 't3_yyfsl1': 1.0, 't3_yj6108': 2.0, 't3_yj7qtb': 1.0}, 'cariimejia16': {'t3_xd45aa': 1.0, 't3_xctko8': 1.0, 't3_x7axjc': 1.0, 't3_x0kupt': 3.0, 't3_x08xy4': 1.0, 't3_vsq3gy': 1.0, 't3_vrczwu': 1.0, 't3_vp62i2': 1.0, 't3_vgrj5s': 1.0, 't3_vbbl7e': 1.0, 't3_vap0pf': 1.0, 't3_v9g9yp': 2.0}, 'ElkNo1598': {'t3_sbw1ly': 1.0, 't3_s94v91': 1.0, 't3_q8pwf8': 4.0, 't3_q8qhtq': 1.0, 't3_q7eev3': 3.0, 't3_q5dlz8': 1.0, 't3_q5axvq': 1.0, 't3_q24n1q': 1.0, 't3_pniboq': 1.0}, 'Adorable_Suggestion4': {'t3_w9i59c': 1.0, 't3_u3oz8x': 1.0, 't3_u3hg2d': 2.0, 't3_t42t9m': 1.0, 't3_s94v91': 1.0, 't3_rwu7ag': 2.0, 't3_rvyzsn': 1.0}, 'PawBud': {'t3_waa46x': 1.0, 't3_up5vlc': 1.0, 't3_w2r3n4': 1.0, 't3_vftxqc': 1.0, 't3_uhzs61': 1.0, 't3_u579an': 1.0, 't3_ry2ukv': 1.0, 't3_tpz85n': 1.0, 't3_tpk16p': 1.0, 't3_t95mdc': 1.0, 't3_siij97': 1.0, 't3_lzwuvd': 1.0, 't3_svzla6': 1.0, 't3_s94v91': 1.0, 't3_qvedf4': 1.0}, 'DomDom2002': {'t3_unzb8l': 1.0, 't3_uky1th': 2.0, 't3_ukxynq': 3.0, 't3_sp67vw': 2.0, 't3_ukkigr': 1.0, 't3_q569es': 1.0, 't3_s94v91': 1.0, 't3_sah5lr': 1.0, 't3_t5ytsq': 1.0, 't3_u2kfn2': 2.0}, 'aitahb': {'t3_wp19nr': 1.0, 't3_ul5e9j': 1.0, 't3_ul5jqs': 1.0, 't3_ul5g7e': 1.0, 't3_pdb6qq': 1.0, 't3_sah5lr': 1.0, 't3_s94v91': 1.0, 't3_ry2ukv': 1.0, 't3_qzn8zy': 1.0, 't3_qbbaa1': 1.0, 't3_qf5w1n': 1.0, 't3_q7svqh': 1.0, 't3_q66ip1': 1.0, 't3_q1wvcp': 1.0, 't3_pzvjij': 1.0}, 'DigProgrammatically3': {'t3_xn2ngw': 1.0, 't3_w7j70c': 1.0, 't3_w24yj1': 1.0, 't3_tnlocp': 1.0, 't3_tgvr9b': 1.0, 't3_t11kko': 1.0, 't3_s94v91': 1.0, 't3_gkpunu': 1.0, 't3_r45j5s': 2.0, 't3_nkt19a': 1.0}, 'aythida': {'t3_ui4z05': 1.0, 't3_vbju6j': 1.0, 't3_syvh7l': 1.0, 't3_snagv5': 1.0, 't3_s94v91': 1.0, 't3_s8wqkc': 1.0, 't3_axk65g': 1.0}, 'rexygorl': {'t3_yyowul': 1.0, 't3_yugxmm': 2.0, 't3_yetk5j': 1.0, 't3_y9vy90': 1.0, 't3_y0ttoi': 1.0, 't3_sxq6j1': 3.0, 't3_wdwkns': 1.0, 't3_w8w92e': 1.0, 't3_w4h42x': 1.0, 't3_w4udy8': 1.0, 't3_vxlgsi': 1.0, 't3_uw4h6c': 1.0}, 'redmehalis': {'t3_ylejve': 1.0, 't3_v5lcbl': 1.0, 't3_v208g9': 1.0, 't3_u0p6pp': 1.0, 't3_txosfn': 1.0, 't3_twfnz8': 2.0, 't3_tvedpm': 1.0, 't3_ttkpzh': 7.0}, 'Otherwise_Extreme_59': {'t3_ylelca': 2.0, 't3_ylejve': 1.0}, 'wassup5551': {'t3_ylejve': 1.0, 't3_wmk9kp': 1.0, 't3_m0gl2p': 1.0, 't3_ujjwv2': 2.0, 't3_rpqz1m': 1.0, 't3_rn26zr': 1.0, 't3_rctcko': 1.0, 't3_r26z76': 2.0, 't3_qtr2i3': 1.0, 't3_qpylv9': 3.0, 't3_qhkap7': 1.0}, 'deepshitgoeshere': {'t3_ylejve': 1.0, 't3_xugx1t': 1.0, 't3_jsdvt7': 1.0, 't3_a3h7t2': 3.0, 't3_8h5cgr': 1.0, 't3_84vwdy': 1.0, 't3_80vhiv': 1.0, 't3_7y8q69': 2.0, 't3_7lyrlp': 1.0, 't3_7l3d93': 1.0, 't3_7cgywk': 1.0, 't3_786xee': 1.0}, 'These-Psychology-959': {'t3_z6b5us': 1.0, 't3_z58z1s': 1.0, 't3_z3x92p': 2.0, 't3_yymhsn': 1.0, 't3_ylejve': 1.0, 't3_z0b01e': 2.0, 't3_yvwtzy': 1.0, 't3_z0ffra': 1.0, 't3_ho7ki7': 1.0, 't3_vqn3c3': 1.0, 't3_vob7ek': 1.0}, 'macedoineGontran': {'t3_uitntu': 1.0, 't3_uglgxo': 1.0, 't3_r7z1e1': 1.0, 't3_r7vy1v': 3.0, 't3_r4da93': 1.0, 't3_r4dgrr': 2.0, 't3_r1yelu': 3.0, 't3_nkt19a': 1.0, 't3_qyv5iw': 2.0}, 'Thenextelonmusklol': {'t3_vav6iv': 1.0, 't3_oafzk3': 2.0, 't3_nc8z12': 1.0, 't3_nev3t9': 3.0, 't3_nc6ryc': 4.0, 't3_nb04rb': 2.0, 't3_n5eeid': 2.0}, 'nfp267': {'t3_mwgump': 1.0, 't3_ntzm9h': 4.0, 't3_nulizp': 2.0, 't3_nul5rk': 1.0, 't3_nuknfv': 3.0, 't3_nu4xwo': 1.0, 't3_np7bul': 1.0, 't3_nufqji': 1.0, 't3_l0cptp': 1.0}, 'amaxs': {'t3_z8wpnq': 1.0, 't3_z9f9v7': 3.0, 't3_z2tbic': 3.0, 't3_wwwptp': 3.0, 't3_w2qp9a': 1.0, 't3_w2l30w': 1.0, 't3_v2fb4w': 1.0, 't3_vl5iyd': 1.0, 't3_vjtrgv': 1.0}, 'ImAClosetNerd': {'t3_y102w8': 1.0, 't3_xvn88c': 1.0, 't3_xz15cl': 1.0, 't3_uuus67': 2.0, 't3_wcsg5d': 1.0, 't3_tm9ztg': 1.0, 't3_tbeh88': 2.0, 't3_tb2clm': 2.0, 't3_jbmtyb': 3.0, 't3_swks2b': 1.0}, 'Agreeable_Baseball87': {'t3_las9g6': 1.0, 't3_l3gypa': 2.0, 't3_la1cgx': 2.0, 't3_lajlim': 1.0, 't3_laq0sk': 1.0, 't3_lapj7b': 1.0, 't3_lafuc4': 3.0, 't3_laod7e': 1.0, 't3_laf38q': 3.0}, 'whocares4817': {'t3_z3ij7l': 1.0, 't3_y2d07w': 1.0, 't3_xq6pf8': 1.0, 't3_xmkit2': 1.0, 't3_wt5abd': 1.0, 't3_vqguhg': 1.0, 't3_vl5a8h': 1.0, 't3_vdeo0v': 1.0, 't3_vba23u': 2.0, 't3_v3wq86': 1.0, 't3_v2vw6x': 1.0, 't3_v2xvhz': 1.0, 't3_uo8rf7': 1.0, 't3_uoa2vp': 1.0}, 'Administrative_Fun_6': {'t3_gy7r51': 1.0, 't3_gyylzl': 2.0}}\n"
     ]
    }
   ],
   "source": [
    "# read comments for users, cached so we can reuse the data when modifying the following cells\n",
    "submissions = initializeUserDict('VUAmsterdam', count=15) \n",
    "fillComments(submissions, count=15)\n",
    "print(submissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t3_yfohi6': 'Got accepted into cs program last year, but now it’s numerous fixus', 't3_yvznih': 'Periods in Vrije Universiteit semester?', 't3_yvr3so': 'Masters admissions', 't3_yflph6': 'Studying in Aarhus as an international student', 't3_yepjzg': 'Should I study in Amsterdam or Leiden?', 't3_y3qitw': 'Study abroad full-time or keep studying in my country?', 't3_xfx6c4': 'If you take less than 0.15 does the 3 month rule still apply?', 't3_xfvx2w': 'KARMA 4 KARMA I WILL GIVE BACK INSTANTLY FOR NEXT 2 HOURS', 't3_ugu62f': 'Ian Barseagle calisthenics program', 't3_wqrimu': '[deleted by user]', 't3_wkdua9': 'Adding weight vs reps', 't3_whyrub': 'LPT: When you gave in to unhealthy food craving, immediately record a video of yourself talking about how you feel about it. Say whether it was worth it or not. Next time you feel a craving watch the recorded video, so you can make a better decision based on rationality and not temporary feelings.', 't3_w8i9kw': 'Very confused', 't3_w2p2dm': 'Method to Turbo Boost Your Planche Progress', 't3_t70amu': 'What’s a weird little snack you like making for yourself?', 't3_sz2hr9': 'Programming Wednesdays', 't3_sthcx5': 'Programming Wednesdays', 't3_mv1rn0': 'My review of \" The Glenn Pendlay Method \" by Seb of WeightliftingHouse', 't3_pf9mi6': '[deleted by user]', 't3_z1bd2t': 'ATP TOP 20 ELIMINATION GAME [ROUND 8]. Fritz eliminated.Vote the player with your least favorite gamestyle. More details and link to poll in comment and picture below', 't3_z0cgcd': \"The look on Serbian MFA's interpreter's face when she realised he escaped her\", 't3_ys1ge2': 'Emma Raducanu launches “The Fabulous World of Dior” at Harrods last night.', 't3_y6hbb8': \"Why are almost all techno track I see on the web like 5-7 minute songs? Is it bad when mine are around 2:30 - 3:30? I just want to express the emotion that fit's in around the 3 minutes, any longer i feel like it just get's boring.\", 't3_y5mi3k': 'Post Match Thread: Liverpool 1-0 Manchester City | English Premier League', 't3_xzvvt7': \"Let's play something: Write 4 of your favorite bands and the rest of us must recommend just one for you (based on your tastes).\", 't3_xt4tzt': 'It hurts.', 't3_xrqzm7': 'Why do you think Dwight had a soft spot for Pam? I love this wholesome friendship!', 't3_xpe2gh': 'Djokovic facing a shitstorm on Twitter because of playing in the Tel Aviv open', 't3_xnv7gp': 'What in the 500th economic lever is that wage ?!?!?!?!', 't3_xlhmdv': 'LAVER CUP 2022: Day 1 Discussion Thread', 't3_xjex9m': '5 - Top 5 players with the most through balls in Europe’s top five leagues this season: 17 - Lionel Messi 16 - Neymar Jr 10 - Junya Ito 9 - PEDRI GONZÁLEZ 9 - Joshua Kimmich Vision.', 't3_xewl7n': 'Roger Federer retirement announcement on Instagram', 't3_x7h3j3': 'Last weekend I saw a great DJ play a terrific set without a single song that I enjoyed or ever want to hear again.', 't3_z0wcf0': 'How do the world the coffee machines work?', 't3_yvpwaf': 'How compulsory is attendance in VU for masters?', 't3_y7n5ci': 'What are the easiest courses at VU?', 't3_y1z3ya': 'is this normal?', 't3_xw6lan': 'Two devices with same UDID preventing me from using my device for tests', 't3_xtsjm6': \"Hey, developer of Apollo for Reddit here. I'm doing a completely free iPhone 14 Pro giveaway to commemorate Apollo's big iOS 16 update and new iPhone 14 Pro features. Just leave a comment to enter! 🎉📱\", 't3_xg4c8t': 'do you think it’s possible to obtain the bachelor’s degree in artificial intelligence in three years? any tips to do it?', 't3_x79pz4': 'Laptop for CS', 't3_x8wkae': \"Tim Cook's response to improving Android texting compatibility: 'buy your mom an iPhone' | The company appears to have no plans to fix 'green bubbles' anytime soon.\", 't3_w5z1ro': 'Tips for first year', 't3_wwm5en': 'Books for CS?', 't3_z3nc13': 'Photo software that can detect and tag people/faces...', 't3_w2oqpf': 'University of Liverpool accommodation Heating', 't3_w1qiw4': 'Grandpa and the kid 🤖', 't3_w0o5n7': 'Your Username is something that in 5 years will be true, what will happen to you?', 't3_vy4lzz': \"Alumni of the University of Liverpool who've attended Computer Science Undergraduates\", 't3_vvpcwa': 'Is VU good for CS', 't3_v1p1ew': 'People who still wear mask at school why?', 't3_usxlc5': 'as a introvert how to be confident in any situation?', 't3_upaz89': 'What is a game everyone needs to play?', 't3_uda8sq': 'Where to pick up WN after S1P2?', 't3_uagwv9': 'If you could undo any mistake, what would it be?', 't3_uae7oi': 'If you pressed one random key per second, how long on average would it take to beat the game?', 't3_u6z3fj': 'What are some facts about healthy relationships?', 't3_zbkktr': 'Between Sweden and Denmark we have a bridge that goes above and below water.', 't3_zbllf3': 'International Students, Have you learned dutch by the time you graduated?', 't3_zbdhat': 'Woorden in het Nederlands met de meeste rijmwoorden', 't3_zbjbpq': 'Gamers of Reddit, what video game has the best storyline?', 't3_zbfjo7': 'Zeven jaar na zijn dramatisch geëindigde stage krijgt journalist Geerlof de Mooij een nieuwe kans', 't3_zb0uqh': 'Wat is jouw grootste date-blunder geweest?', 't3_zbblyx': 'Need to know how the selection test for numerus fixus programs are conducted', 't3_zae95r': 'Kanye West suspended from Twitter after posting swastika inside the Star of David', 't3_woefl8': 'God of War Ragnarok full plot leak', 't3_x7zpt6': 'is it normal for my maths teacher... to ask me biology in my exams?', 't3_x3tvkw': 'Is English L&L HL much harder than SL?', 't3_x3f7th': 'Can anyone who’s gotten into GA Tech share their grades and extracurriculars?', 't3_wwhmvf': 'HL/SL AA or AI Maths for Computer/Software related degree', 't3_wrfp81': 'who do you think is taking the WC this year and why?', 't3_wr69gs': 'What can a girl carry to protect herself?', 't3_wqnliu': 'Going to amsterdam without registration', 't3_wrc19a': 'Are my topics fine or complex enough for Math AA HL IA and Chem HL EE?', 't3_wra48h': 'Ho do I get over this? I stay in my room 24/7 felling tired doing nothing.', 't3_wqu19e': 'Will PE be a thing throughout the whole process?', 't3_woo8y9': 'A nanobot helping a sperm with motility issues along towards an egg. These metal helixes are so small they can completely wrap around the tail of a single sperm and assist it along its journey', 't3_wozwp6': 'I dont know man was that really needed', 't3_wk3v24': 'Can someone tell me what‘s going on in this vid, since i can not watch it', 't3_wioy83': 'Do you regret choosing IB? what is the reason for your answer?', 't3_x73x8v': 'Constrained choice and minor availability', 't3_x0v7rc': 'Application Deadline... WUT?', 't3_vqy4i1': \"Question -> VU's Research Master's (Psychology)\", 't3_vujtaj': \"How's the M Artificial Intelligence program?\", 't3_w1ylml': '[deleted by user]', 't3_s6eff5': 'after architecture studies?', 't3_ryq10w': 'Artificial Intelligence bachelors program - how to prepare', 't3_r8gu01': 'Applying for International Relations, Security and Global Order Master’s', 't3_qve8hr': 'Upload a photo of yourself', 't3_o4hg1r': 'AI Bachelors Program - is it difficult to get into?', 't3_mvnx26': 'International students at VU', 't3_jvjsjx': 'Covid affecting work at VU?', 't3_jj0w84': 'This is me', 't3_j3c4hu': 'This is me', 't3_z8qvwn': '[Ticket Buy/Sell] After Hours Till Dawn: World Tour Tickets', 't3_yp00cx': 'How’s my top 10 UK rappers of all time list as an American?', 't3_yob4h6': 'Digga really waited 2 years stacked up a mil to say that loski bar 😭😭', 't3_yoyrzo': 'Looks like bandokay just unlocked a new level and theses pressplay freestyles come like one music video', 't3_ybsmjf': 'AITA for telling my sister to stop taking showers with her husband in my house?', 't3_x7z2us': 'Tekken World tour finals', 't3_y47utx': 'CHALLENGE: Anger a Tekken player using ONLY 2 WORDS', 't3_x36dby': '[Method] Feel like your life is going nowhere? Read this.', 't3_xnyfcm': \"My gf's calves\", 't3_xh3c37': 'what motivates you??????????????', 't3_vmi2r0': \"Any what's app group for CS '22 batch\", 't3_u9x47q': '[deleted by user]', 't3_u2zfdh': 'A cell at the United States Administrative Maximum Penitentiary (more popularly known as ADX Florence). El Chapo is serving a life sentence here.', 't3_tp3n4w': 'Both of Mizormac’s verses on “Still in the field” (unreleased)', 't3_u4563b': 'Master after BSc Computer Science @VU', 't3_ui4z05': 'WhatsApp Group Chat - For Students from India - 2022-23', 't3_v8uxiw': 'CS Curriculum at VU', 't3_isyk53': 'Which album do you think has no bad songs on it, and can be listened all the way through?', 't3_iazsu8': 'My University(TU/e) has asked me to defer my application', 't3_gyylzl': 'Can anyone tell me are you happy with the computer science program', 't3_gxwk04': 'Free Summer Dutch Course in TU/e', 't3_g35ri2': 'How many study program I can accept for conditional offer when I receive offer from Dutch university?', 't3_g41vry': 'Housing options for first year CSE student', 't3_z5w24x': 'perfect timing through luck and patience', 't3_yiq7c7': 'Questions regarding minoxidil usage', 't3_wcjdv2': '[deleted by user]', 't3_vejubw': '[deleted by user]', 't3_vap0pf': 'Housing by VU', 't3_v5kkhf': 'Looking for a room/roommates in Amsterdam?', 't3_rqna7u': 'Non picky eaters, what’s a food you just cannot do?', 't3_r526ca': 'Breaking three month rule for molly once? Or just stick to acid for bush doof', 't3_r2vabj': '[deleted by user]', 't3_quqcdz': 'Needing Opinions on Weed Usage', 't3_qtvvwj': '[deleted by user]', 't3_qrxn3d': 'What duration / dosing of kratom elicits withdrawals?', 't3_nz1yo6': 'Season Edit/ What do you think ? (skiing in the park since 1.5 years)', 't3_z66q0i': 'smoking herbs', 't3_z6ttro': 'About 0.5g of ice-cream cake', 't3_yyfsl1': 'I am international student here in Amsterdam and just wanted to buy a watch for my father 🙂. Is that normal behaviour I mean I genuinely feel offended.', 't3_yj6108': 'Japanese Peaches (Terps Army) : Whitest Ash ever', 't3_yj7qtb': 'Are you happy with the current state of how weed is regulated in the Netherlands?', 't3_xd45aa': 'What are some deals that all students studying in The Netherlands should know about?', 't3_xctko8': 'Psychology books first year students?', 't3_x7axjc': 'SAT and IGCSE', 't3_x0kupt': '[deleted by user]', 't3_x08xy4': 'Loneliness loneliness loneliness', 't3_vsq3gy': 'How to send the baccalaureate diploma', 't3_vrczwu': 'i’m an indian student considering doing bachelors in Netherlands (2023) and I have a couple of questions', 't3_vp62i2': \"Is it over if I haven't found housing already? What can I do to find housing before September?\", 't3_vgrj5s': 'Questions surviving the first few days in The Netherlands.', 't3_vbbl7e': 'Choosing a place to live for a first-year student', 't3_v9g9yp': '[deleted by user]', 't3_sbw1ly': 'Studying as an international student in the Netherlands', 't3_s94v91': 'Looking for people going to VU from India this year', 't3_q8pwf8': 'I don´t know how to resolve exercise, that I have to create a dictionary', 't3_q8qhtq': 'Help, I don´t know how to resolve exercise', 't3_q7eev3': \"Help!! I am doing this exercise for an assignment at school where I have three files, but I don´t see what's wrong with the code it prints things that shouldnt\", 't3_q5dlz8': \"Help!! I am doing this exercise for an assignment at school where I have three files, but I don´t see what's wrong with the code it doesn't print the three mapping_lists\", 't3_q5axvq': \"Help!! I am doing this exercise for an assignment at school where I have three files, but I don´t see what's wrong with the code it doesn't print the three mapping_lists\", 't3_q24n1q': 'Help!! I am doing this exercice below where i have three files, but I don´t see whats wrong', 't3_pniboq': 'need help with this question', 't3_w9i59c': 'PHIL 115', 't3_u3oz8x': 'Has anyone been accepted for commerce yet?', 't3_u3hg2d': 'I AM REALLY EXCITED!', 't3_t42t9m': 'Incoming Class and Admissions Megathread - Got Questions? Ask them in here!', 't3_rwu7ag': 'Whatsapp group', 't3_rvyzsn': 'the Holland Scholarship', 't3_waa46x': 'Probably a Noob Q/ issue. Cue track comin out speaker/ pc', 't3_up5vlc': 'DDJ 400. Master output plays cue.', 't3_w2r3n4': 'CIA💀💀💀💀💀', 't3_vftxqc': 'I need your help!!!', 't3_uhzs61': 'Today morning at KPHB Raintree park', 't3_u579an': 'Does anyone know until when we can cancel our application in study link?', 't3_ry2ukv': 'Calling out MSc CS VU-UvA folks', 't3_tpz85n': '[deleted by user]', 't3_tpk16p': '💙', 't3_t95mdc': 'Riding bikes is for pussies amirite?', 't3_siij97': 'How to Crack GSOC 2022?', 't3_lzwuvd': 'Macbook not sleeping when lid is closed', 't3_svzla6': 'Parasite being removed from a praying mantis.', 't3_qvedf4': 'Recommendation letters', 't3_unzb8l': '[deleted by user]', 't3_uky1th': 'Need a little advice', 't3_ukxynq': 'Advice for shoe type', 't3_sp67vw': 'A discord server for “The newly admitted” CS/AI students', 't3_ukkigr': \"How do lazy students get their assignments done on time? My roommate is this lazy student yet I've never heard claims of him missing an exam or an assignment\", 't3_q569es': 'Computer Science at VU Amsterdam', 't3_sah5lr': 'excited and scared - girl from Los Angeles, California', 't3_t5ytsq': 'Leiden Admission Question', 't3_u2kfn2': 'Credit Transfer', 't3_wp19nr': 'Postgres table transformation: transposing values of a column into new columns', 't3_ul5e9j': 'Connection Refused while connecting to upstream (nginx + uwsgi)', 't3_ul5jqs': 'Connection Refused while connecting to upstream (nginx + uwsgi + django)', 't3_ul5g7e': 'Connection Refused while connecting to upstream (nginx + uwsgi)', 't3_pdb6qq': 'Where to buy stationery in Amsterdam?', 't3_qzn8zy': '[deleted by user]', 't3_qbbaa1': 'Application for TUM 22 SS Informatics', 't3_qf5w1n': '[deleted by user]', 't3_q7svqh': '[deleted by user]', 't3_q66ip1': '[deleted by user]', 't3_q1wvcp': 'Confused about VPD', 't3_pzvjij': '[deleted by user]', 't3_xn2ngw': 'Who wants to watch me cum for Peyton List?', 't3_w7j70c': 'Accidental Indoor flood', 't3_w24yj1': 'IELTS Academic Computer Based', 't3_tnlocp': 'Alcohol Addiction - HELP!', 't3_tgvr9b': 'Anyone has experience with applying to the Orientation Search Year (Zoekjaar) Visa for non-EU students who graduated from a Dutch university?', 't3_t11kko': 'Help with Application Form Format?', 't3_gkpunu': 'Trinity College Dublin or University of Edinburgh?', 't3_r45j5s': 'MSc computer science from VU Amsterdam for', 't3_nkt19a': 'CS chat room for students', 't3_vbju6j': 'Abuse of power is too infuriating.', 't3_syvh7l': \"Don't go out in the nights :)\", 't3_snagv5': \"Girl asked if I had any valentine's day plans\", 't3_s8wqkc': 'What are you doing during resting between sets?', 't3_axk65g': 'This dance move', 't3_yyowul': 'looking for a mentor', 't3_yugxmm': 'Anyone with tickets for still woozy Amsterdam 21st November?!', 't3_yetk5j': 'amsterdam show 21 nov concert buddy', 't3_y9vy90': 'Good Resources To Use For Learning Bioinformatics In Python', 't3_y0ttoi': 'Tickets for Amsterdam Paradiso concert🥺', 't3_sxq6j1': 'Ticket needed for the Amsterdam Gig', 't3_wdwkns': 'Who was Elaine’s handsomest boyfriend or love interest?', 't3_w8w92e': 'Goodie bag 🍄', 't3_w4h42x': 'Spooky Marvin - ‘What U Want!’', 't3_w4udy8': 'Found this guy in central station. Left him on the exit turnstile. Hope he finds his way home', 't3_vxlgsi': 'discord server?', 't3_uw4h6c': 'New festival', 't3_ylejve': 'Computer Science at VU', 't3_v5lcbl': 'When the company completely silent on anti LGBT laws in their home state tries to say they care', 't3_v208g9': 'Str8 guy but only watch porn with a bd', 't3_u0p6pp': 'Πως να φερω γκομενω σπιτι μου χωρις να νομιζει οτι θελω σεξ;', 't3_txosfn': 'What is your least favorite European country?', 't3_twfnz8': 'Уште еднаш, голема благодарност до сите кои што беа инволвирани во цртањето на македонското знаме во r/place! Се гледаме следна пат кога ќе биде отворен r/place.', 't3_tvedpm': 'Τι παίζει με το οπίσθιο τρίψιμο στα clubs?', 't3_ttkpzh': '[deleted by user]', 't3_ylelca': 'VU vs TU Delft', 't3_wmk9kp': 'Recommend me laptops', 't3_m0gl2p': 'Guys I keep relapsing help me. I hate masturbation.', 't3_ujjwv2': 'I have a question.', 't3_rpqz1m': 'who was it for yall', 't3_rn26zr': 'Im just so tired and depressed.', 't3_rctcko': 'Hello! I have an urgent question! Especially to those who got accepted to VU Amsterdam!!!', 't3_r26z76': 'Guys I need help!!!', 't3_qtr2i3': 'Accepting offers from different unis HELP', 't3_qpylv9': 'over at r/fucktravisscott things have taken a turn for the racist', 't3_qhkap7': 'What pisses you off when eating?', 't3_xugx1t': 'Searching for some cool (tech) events to do for a 15 year old.', 't3_jsdvt7': 'When to start applying for summer internships in IT in Finland?', 't3_a3h7t2': 'please help me end my suffering', 't3_8h5cgr': 'Constant slowness, crashing, and random reboots on OnePlus One', 't3_84vwdy': 'My Space Oddity 30% is complete!', 't3_80vhiv': 'Anyone interested in a Berlin meet up?', 't3_7y8q69': 'blurry pictures of my first and second attempt today', 't3_7lyrlp': 'TIL a 2013 BBC study found that 56% of pilots fell asleep while flying, and 29% had woken up to find the co-pilot also asleep.', 't3_7l3d93': 'What’s a tradition that people know that is slowly fading away?', 't3_7cgywk': 'Installation is rather expensive if you ask me', 't3_786xee': 'BIKES exhibition 22 June - 1 October 2017, Grassi Museum Leipzig, Germany', 't3_z6b5us': 'Number of applicants on the bachelor \"Computer Science and Engineering\"', 't3_z58z1s': 'Question about Computer Science programs.', 't3_z3x92p': 'NUMERUS FIXUS OR NOT / COMPUTER SCIENCE', 't3_yymhsn': 'cs in the netherlands', 't3_z0b01e': 'Selection procedure for Bachelor Computer Science and Engineering', 't3_yvwtzy': 'How hard is it to get into the bachelor of Computer Science and Engineering?', 't3_z0ffra': 'How long did it take you to get an answer from the university after you’ve applied?', 't3_ho7ki7': 'TU Delft and Eindhoven CSE selection test similarity?', 't3_vqn3c3': 'Reprocessed an old favorite. See you next year, M42', 't3_vob7ek': 'New algorithm can predict future crime a week in advance, with 90% accuracy', 't3_uitntu': '[doctrine] Returning row even if join is empty', 't3_uglgxo': 'Using a ionic component outside of a ionic project', 't3_r7z1e1': 'No option to compress/uncompress folder/file', 't3_r7vy1v': 'Trying to get mysql/mariadb server start with openRC', 't3_r4da93': 'Weird sms I received', 't3_r4dgrr': 'Quasar app, missing some modules after npm install', 't3_r1yelu': 'Small icon problem in dolphin', 't3_qyv5iw': '[deleted by user]', 't3_vav6iv': '[deleted by user]', 't3_oafzk3': 'What courses are needed for Aerospace/Mechanical engineering?', 't3_nc8z12': 'Accommodation Uilenstede', 't3_nev3t9': 'Transferring from ME Bachelor at VU Amsterdam to University of Twente', 't3_nc6ryc': 'VU Amsterdam Uilenstede housing', 't3_nb04rb': 'First year syllabus bachelor mechanical engineering', 't3_n5eeid': 'Housing', 't3_mwgump': 'Getting more informations about computer science', 't3_ntzm9h': 'Sad and Lonely.', 't3_nulizp': '15F, very soon 16 here :)', 't3_nul5rk': \"16F (almost 17) can't sleep. Looking for [friendship] maybe long term, we will see\", 't3_nuknfv': '[deleted by user]', 't3_nu4xwo': '[crushes] friend confessed on a whim then basically said it was a mistake', 't3_np7bul': 'How to handle (possible) rejection?', 't3_nufqji': '(17M) I just want a friend that I can talk to.', 't3_l0cptp': 'Need Contacts', 't3_z8wpnq': 'Tulane vs. Parsons Dual Degree', 't3_z9f9v7': \"Are there (transnational) joint PhD's in the United States?\", 't3_z2tbic': '[IWantOut] 23M Policy/Politics USA -> EU', 't3_wwwptp': 'American political scientists: Can I get a foreign PhD?', 't3_w2qp9a': 'Unipartite and bipartite network in one?', 't3_w2l30w': 'Will university look past a couple of deficiencies if I have a 4.0 in my 2 year college', 't3_v2fb4w': '[Topic][Open] Open Discussion Thread — Anybody can post a general visualization question or start a fresh discussion!', 't3_vl5iyd': 'Best brew when I have to sneak coffee in?', 't3_vjtrgv': 'Looking to move to another country as a 21 year old American', 't3_y102w8': 'It appears my S8 is dying. RIP.', 't3_xvn88c': 'Is S22 worth it?', 't3_xz15cl': 'Cats On Glass Tables', 't3_uuus67': 'A Perfect Pairing starring Victoria Justice & Adam Demos | Official Trailer | Netflix | Out Now', 't3_wcsg5d': 'Dove Jones Marketing', 't3_tm9ztg': 'Very Sexy Nala beans', 't3_tbeh88': 'sony wh-1000xm4 noise cancellation headphones', 't3_tb2clm': 'Thinkpad P15 intermittently drops wifi connection', 't3_jbmtyb': 'How to disable all WH1000-XM4 voice prompts', 't3_swks2b': 'I get very overwhelmed with prioritizing which assignments to do first and other non school related stuff', 't3_las9g6': 'Does VU Amsterdam require a student essay? Or not?', 't3_l3gypa': 'Moving to Amsterdam in September', 't3_la1cgx': 'Question about Holland international study center', 't3_lajlim': 'Moving to the Netherlands and learning Dutch as an Englishman', 't3_laq0sk': 'ECON30001 & ECON30018', 't3_lapj7b': 'Question about Trinity college and the University of Melbourne', 't3_lafuc4': 'Will the Netherlands borders be open for new international students next year?', 't3_laod7e': 'DPT Timetabling Problem', 't3_laf38q': 'Question about the Holland international study canter and VU university Amsterdam', 't3_z3ij7l': \"What is one detail you'd like to see in Book 3?\", 't3_y2d07w': 'What is the hardest and coldest line in the whole show in your opinion?', 't3_xq6pf8': \"I'm not sure whether I hallucinated an episode of Adventure Time\", 't3_xmkit2': 'Other Benders and being blind', 't3_wt5abd': \"Anyone notice Finn's gauntlet from Adventure Time in Mr. Needful's shop.\", 't3_vqguhg': 'If you had the choice to make an Adventure Time spinoff what would it be about??', 't3_vl5a8h': 'Spooky Episode Question.', 't3_vdeo0v': 'Susan and Freda > Fionna and Cake', 't3_vba23u': 'Regular show missing episodes on HBO max', 't3_v3wq86': \"What's a movie where the potential couple doesn't actually end up together?\", 't3_v2vw6x': 'Is Jake weak to spider silk?', 't3_v2xvhz': 'Write down your favorite adventure time episode and why!!', 't3_uo8rf7': 'TIL of John Graham, who hated his mother so much he hid 25 sticks of dynamite and a timed detonator in her suitcase before a flight. It was one of the first ever attacks of a commercial flight; all 44 aboard died.', 't3_uoa2vp': \"Don't take it seriously\", 't3_gy7r51': 'Tourists/Visitors/New Residents: Q&A Thread for the week of June 07'}\n"
     ]
    }
   ],
   "source": [
    "# extract titles to submissions from above\n",
    "submission_titles = {}\n",
    "\n",
    "for _, user_submissions in submissions.items():\n",
    "    for submission in user_submissions:\n",
    "        submission_titles[submission] = praw.models.Submission(r, id=submission[3:]).title\n",
    "\n",
    "print(submission_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts Similar to Posts the User Otherwise_Extreme_59 commented on:\n",
      "\tComputer Science at VU Amsterdam (Similarity: 0.8)\n",
      "\tMaster after BSc Computer Science @VU (Similarity: 0.375)\n",
      "\tCS Curriculum at VU (Similarity: 0.3333333333333333)\n",
      "\tInternational students at VU (Similarity: 0.3333333333333333)\n",
      "\tQuestion about Computer Science programs. (Similarity: 0.25)\n"
     ]
    }
   ],
   "source": [
    "# RECOMMENDING POSTS SIMILAR TO POSTS A USER COMMENTED ON\n",
    "\n",
    "# choose user with at least one other similar user(s) with no comments on posts that were deleted\n",
    "# this is not necessary, but ensures that we don't only recommend deleted posts, as all deleted posts have the same text: [deleted by user]\n",
    "while True:\n",
    "\n",
    "    # select random user\n",
    "    chosen_user = choice(list(users.keys()))\n",
    "\n",
    "    # get all submissions the user commented on\n",
    "    user_submissions = set(submissions[chosen_user].keys())\n",
    "\n",
    "    # check all posts are still available and were not deleted\n",
    "    if not any(submission_titles[submission] == \"[deleted by user]\" for submission in user_submissions):\n",
    "        break\n",
    "\n",
    "# get all submissions any user commented on\n",
    "submissions_ids = set()\n",
    "for _, ids in submissions.items():\n",
    "    for id in ids:\n",
    "        submissions_ids.add(id)\n",
    "\n",
    "# get all submissions any user but not the chosen user commented on\n",
    "other_submissions = submissions_ids.difference(user_submissions)\n",
    "\n",
    "# claculate similarity of submission titles based on Jaccard Similarity to the posts the chosen user commented on, and return the maximum similarity\n",
    "def user_submission_similarity(submission):\n",
    "    ratings = []\n",
    "    for user_submission in user_submissions:\n",
    "        l1, l2 = compare(submission_titles[submission], submission_titles[user_submission])\n",
    "        ratings.append(get_jaccard_sim(l1,l2))\n",
    "    return max(ratings)\n",
    "\n",
    "# map all submissions to their similarity with any of the users submissions\n",
    "rated_submissions = {submission: user_submission_similarity(submission) for submission in other_submissions}\n",
    "# sort submissions by rating\n",
    "final_recommendations = dict(list(reversed(sorted(rated_submissions.items(), key=lambda item: item[1])))[:5])\n",
    "\n",
    "print(f\"Posts Similar to Posts the User '{chosen_user}' commented on:\")\n",
    "for submission, rating in final_recommendations.items():\n",
    "    print(f\"\\t{submission_titles[submission]} (Similarity: {rating})\")\n",
    "\n",
    "# Recommend posts for user based on what posts similar users have commennted on\n",
    "#red_users = initializeUserDict('VUAmsterdam', count=15) \n",
    "#fillComments(red_users, count=15)\n",
    "#print(getRecommendations(user, prefs=red_users))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1f605b58165b91266968540af11c3ac3fd4bf13be1051127cb18d55d34fa23b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
